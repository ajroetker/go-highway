// Code generated by github.com/ajroetker/go-highway/cmd/hwygen. DO NOT EDIT.

//go:build amd64 && goexperiment.simd

package nn

import (
	stdmath "math"
	"simd/archsimd"
	"unsafe"

	"github.com/ajroetker/go-highway/hwy"
	"github.com/ajroetker/go-highway/hwy/asm"
	"github.com/ajroetker/go-highway/hwy/contrib/math"
)

func BaseSDPA_avx2_Float16(q []hwy.Float16, k []hwy.Float16, v []hwy.Float16, mask []hwy.Float16, scores []hwy.Float16, output []hwy.Float16, seqLen int, kvLen int, headDim int, scale hwy.Float16) {
	if seqLen == 0 || kvLen == 0 || headDim == 0 {
		return
	}
	lanes := 8
	for i := range seqLen {
		qOff := i * headDim
		sOff := i * kvLen
		j := 0
		for ; j+4 <= kvLen; j += 4 {
			acc0 := asm.ZeroFloat16x8AVX2()
			acc1 := asm.ZeroFloat16x8AVX2()
			acc2 := asm.ZeroFloat16x8AVX2()
			acc3 := asm.ZeroFloat16x8AVX2()
			kOff0 := j * headDim
			kOff1 := (j + 1) * headDim
			kOff2 := (j + 2) * headDim
			kOff3 := (j + 3) * headDim
			p := 0
			for ; p+lanes <= headDim; p += lanes {
				vQ := asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&q[qOff+p:][0]))
				acc0 = vQ.MulAdd(asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&k[kOff0+p:][0])), acc0)
				acc1 = vQ.MulAdd(asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&k[kOff1+p:][0])), acc1)
				acc2 = vQ.MulAdd(asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&k[kOff2+p:][0])), acc2)
				acc3 = vQ.MulAdd(asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&k[kOff3+p:][0])), acc3)
			}
			s0 := acc0.ReduceSum()
			s1 := acc1.ReduceSum()
			s2 := acc2.ReduceSum()
			s3 := acc3.ReduceSum()
			for ; p < headDim; p++ {
				qp := q[qOff+p]
				s0 += qp.Float32() * k[kOff0+p].Float32()
				s1 += qp.Float32() * k[kOff1+p].Float32()
				s2 += qp.Float32() * k[kOff2+p].Float32()
				s3 += qp.Float32() * k[kOff3+p].Float32()
			}
			scores[sOff+j] = hwy.Float32ToFloat16(s0 * scale.Float32())
			scores[sOff+j+1] = hwy.Float32ToFloat16(s1 * scale.Float32())
			scores[sOff+j+2] = hwy.Float32ToFloat16(s2 * scale.Float32())
			scores[sOff+j+3] = hwy.Float32ToFloat16(s3 * scale.Float32())
		}
		for ; j < kvLen; j++ {
			kOff := j * headDim
			acc := asm.ZeroFloat16x8AVX2()
			p := 0
			for ; p+lanes <= headDim; p += lanes {
				vQ := asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&q[qOff+p:][0]))
				vK := asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&k[kOff+p:][0]))
				acc = vQ.MulAdd(vK, acc)
			}
			sum := acc.ReduceSum()
			for ; p < headDim; p++ {
				sum += q[qOff+p].Float32() * k[kOff+p].Float32()
			}
			scores[sOff+j] = hwy.Float32ToFloat16(sum * scale.Float32())
		}
		if mask != nil {
			mOff := i * kvLen
			si := 0
			for ; si+lanes <= kvLen; si += lanes {
				s := asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&scores[sOff+si:][0]))
				m := asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&mask[mOff+si:][0]))
				s.Add(m).StorePtr(unsafe.Pointer(&scores[sOff+si:][0]))
			}
			for ; si < kvLen; si++ {
				scores[sOff+si] = hwy.Float32ToFloat16(scores[sOff+si].Float32() + mask[mOff+si].Float32())
			}
		}
		maxVal := scores[sOff]
		for j := 1; j < kvLen; j++ {
			if scores[sOff+j].Float32() > maxVal.Float32() {
				maxVal = scores[sOff+j]
			}
		}
		vMax := asm.BroadcastFloat16x8AVX2(uint16(maxVal))
		sumAcc := asm.ZeroFloat16x8AVX2()
		si := 0
		for ; si+lanes <= kvLen; si += lanes {
			x := asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&scores[sOff+si:][0]))
			shifted := x.Sub(vMax)
			expVal := math.BaseExpVec_avx2_Float16(shifted)
			expVal.StorePtr(unsafe.Pointer(&scores[sOff+si:][0]))
			sumAcc = sumAcc.Add(expVal)
		}
		expSum := sumAcc.ReduceSum()
		for ; si < kvLen; si++ {
			scores[sOff+si] = hwy.Float32ToFloat16(float32(stdmath.Exp(float64(scores[sOff+si].Float32() - maxVal.Float32()))))
			expSum += scores[sOff+si].Float32()
		}
		invSum := hwy.Float32ToFloat16(float32(1.0) / expSum)
		vInvSum := asm.BroadcastFloat16x8AVX2(uint16(invSum))
		si = 0
		for ; si+lanes <= kvLen; si += lanes {
			x := asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&scores[sOff+si:][0]))
			x.Mul(vInvSum).StorePtr(unsafe.Pointer(&scores[sOff+si:][0]))
		}
		for ; si < kvLen; si++ {
			scores[sOff+si] = hwy.Float32ToFloat16(scores[sOff+si].Float32() * invSum.Float32())
		}
		oOff := i * headDim
		tileD := 4 * lanes
		d := 0
		for ; d+tileD <= headDim; d += tileD {
			acc0 := asm.ZeroFloat16x8AVX2()
			acc1 := asm.ZeroFloat16x8AVX2()
			acc2 := asm.ZeroFloat16x8AVX2()
			acc3 := asm.ZeroFloat16x8AVX2()
			for j := range kvLen {
				vS := asm.BroadcastFloat16x8AVX2(uint16(scores[sOff+j]))
				vRow := v[j*headDim:]
				acc0 = vS.MulAdd(asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&vRow[d:][0])), acc0)
				acc1 = vS.MulAdd(asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&vRow[d+lanes:][0])), acc1)
				acc2 = vS.MulAdd(asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&vRow[d+2*lanes:][0])), acc2)
				acc3 = vS.MulAdd(asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&vRow[d+3*lanes:][0])), acc3)
			}
			acc0.StorePtr(unsafe.Pointer(&output[oOff+d:][0]))
			acc1.StorePtr(unsafe.Pointer(&output[oOff+d+lanes:][0]))
			acc2.StorePtr(unsafe.Pointer(&output[oOff+d+2*lanes:][0]))
			acc3.StorePtr(unsafe.Pointer(&output[oOff+d+3*lanes:][0]))
		}
		for ; d+lanes <= headDim; d += lanes {
			acc := asm.ZeroFloat16x8AVX2()
			for j := range kvLen {
				vS := asm.BroadcastFloat16x8AVX2(uint16(scores[sOff+j]))
				acc = vS.MulAdd(asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&v[j*headDim+d:][0])), acc)
			}
			acc.StorePtr(unsafe.Pointer(&output[oOff+d:][0]))
		}
		for ; d < headDim; d++ {
			var sum float32
			for j := range kvLen {
				sum += scores[sOff+j].Float32() * v[j*headDim+d].Float32()
			}
			output[oOff+d] = hwy.Float32ToFloat16(sum)
		}
	}
}

func BaseSDPA_avx2_BFloat16(q []hwy.BFloat16, k []hwy.BFloat16, v []hwy.BFloat16, mask []hwy.BFloat16, scores []hwy.BFloat16, output []hwy.BFloat16, seqLen int, kvLen int, headDim int, scale hwy.BFloat16) {
	if seqLen == 0 || kvLen == 0 || headDim == 0 {
		return
	}
	lanes := 8
	for i := range seqLen {
		qOff := i * headDim
		sOff := i * kvLen
		j := 0
		for ; j+4 <= kvLen; j += 4 {
			acc0 := asm.ZeroBFloat16x8AVX2()
			acc1 := asm.ZeroBFloat16x8AVX2()
			acc2 := asm.ZeroBFloat16x8AVX2()
			acc3 := asm.ZeroBFloat16x8AVX2()
			kOff0 := j * headDim
			kOff1 := (j + 1) * headDim
			kOff2 := (j + 2) * headDim
			kOff3 := (j + 3) * headDim
			p := 0
			for ; p+lanes <= headDim; p += lanes {
				vQ := asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&q[qOff+p:][0]))
				acc0 = vQ.MulAdd(asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&k[kOff0+p:][0])), acc0)
				acc1 = vQ.MulAdd(asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&k[kOff1+p:][0])), acc1)
				acc2 = vQ.MulAdd(asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&k[kOff2+p:][0])), acc2)
				acc3 = vQ.MulAdd(asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&k[kOff3+p:][0])), acc3)
			}
			s0 := acc0.ReduceSum()
			s1 := acc1.ReduceSum()
			s2 := acc2.ReduceSum()
			s3 := acc3.ReduceSum()
			for ; p < headDim; p++ {
				qp := q[qOff+p]
				s0 += qp.Float32() * k[kOff0+p].Float32()
				s1 += qp.Float32() * k[kOff1+p].Float32()
				s2 += qp.Float32() * k[kOff2+p].Float32()
				s3 += qp.Float32() * k[kOff3+p].Float32()
			}
			scores[sOff+j] = hwy.Float32ToBFloat16(s0 * scale.Float32())
			scores[sOff+j+1] = hwy.Float32ToBFloat16(s1 * scale.Float32())
			scores[sOff+j+2] = hwy.Float32ToBFloat16(s2 * scale.Float32())
			scores[sOff+j+3] = hwy.Float32ToBFloat16(s3 * scale.Float32())
		}
		for ; j < kvLen; j++ {
			kOff := j * headDim
			acc := asm.ZeroBFloat16x8AVX2()
			p := 0
			for ; p+lanes <= headDim; p += lanes {
				vQ := asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&q[qOff+p:][0]))
				vK := asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&k[kOff+p:][0]))
				acc = vQ.MulAdd(vK, acc)
			}
			sum := acc.ReduceSum()
			for ; p < headDim; p++ {
				sum += q[qOff+p].Float32() * k[kOff+p].Float32()
			}
			scores[sOff+j] = hwy.Float32ToBFloat16(sum * scale.Float32())
		}
		if mask != nil {
			mOff := i * kvLen
			si := 0
			for ; si+lanes <= kvLen; si += lanes {
				s := asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&scores[sOff+si:][0]))
				m := asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&mask[mOff+si:][0]))
				s.Add(m).StorePtr(unsafe.Pointer(&scores[sOff+si:][0]))
			}
			for ; si < kvLen; si++ {
				scores[sOff+si] = hwy.Float32ToBFloat16(scores[sOff+si].Float32() + mask[mOff+si].Float32())
			}
		}
		maxVal := scores[sOff]
		for j := 1; j < kvLen; j++ {
			if scores[sOff+j].Float32() > maxVal.Float32() {
				maxVal = scores[sOff+j]
			}
		}
		vMax := asm.BroadcastBFloat16x8AVX2(uint16(maxVal))
		sumAcc := asm.ZeroBFloat16x8AVX2()
		si := 0
		for ; si+lanes <= kvLen; si += lanes {
			x := asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&scores[sOff+si:][0]))
			shifted := x.Sub(vMax)
			expVal := math.BaseExpVec_avx2_BFloat16(shifted)
			expVal.StorePtr(unsafe.Pointer(&scores[sOff+si:][0]))
			sumAcc = sumAcc.Add(expVal)
		}
		expSum := sumAcc.ReduceSum()
		for ; si < kvLen; si++ {
			scores[sOff+si] = hwy.Float32ToBFloat16(float32(stdmath.Exp(float64(scores[sOff+si].Float32() - maxVal.Float32()))))
			expSum += scores[sOff+si].Float32()
		}
		invSum := hwy.Float32ToBFloat16(float32(1.0) / expSum)
		vInvSum := asm.BroadcastBFloat16x8AVX2(uint16(invSum))
		si = 0
		for ; si+lanes <= kvLen; si += lanes {
			x := asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&scores[sOff+si:][0]))
			x.Mul(vInvSum).StorePtr(unsafe.Pointer(&scores[sOff+si:][0]))
		}
		for ; si < kvLen; si++ {
			scores[sOff+si] = hwy.Float32ToBFloat16(scores[sOff+si].Float32() * invSum.Float32())
		}
		oOff := i * headDim
		tileD := 4 * lanes
		d := 0
		for ; d+tileD <= headDim; d += tileD {
			acc0 := asm.ZeroBFloat16x8AVX2()
			acc1 := asm.ZeroBFloat16x8AVX2()
			acc2 := asm.ZeroBFloat16x8AVX2()
			acc3 := asm.ZeroBFloat16x8AVX2()
			for j := range kvLen {
				vS := asm.BroadcastBFloat16x8AVX2(uint16(scores[sOff+j]))
				vRow := v[j*headDim:]
				acc0 = vS.MulAdd(asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&vRow[d:][0])), acc0)
				acc1 = vS.MulAdd(asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&vRow[d+lanes:][0])), acc1)
				acc2 = vS.MulAdd(asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&vRow[d+2*lanes:][0])), acc2)
				acc3 = vS.MulAdd(asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&vRow[d+3*lanes:][0])), acc3)
			}
			acc0.StorePtr(unsafe.Pointer(&output[oOff+d:][0]))
			acc1.StorePtr(unsafe.Pointer(&output[oOff+d+lanes:][0]))
			acc2.StorePtr(unsafe.Pointer(&output[oOff+d+2*lanes:][0]))
			acc3.StorePtr(unsafe.Pointer(&output[oOff+d+3*lanes:][0]))
		}
		for ; d+lanes <= headDim; d += lanes {
			acc := asm.ZeroBFloat16x8AVX2()
			for j := range kvLen {
				vS := asm.BroadcastBFloat16x8AVX2(uint16(scores[sOff+j]))
				acc = vS.MulAdd(asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&v[j*headDim+d:][0])), acc)
			}
			acc.StorePtr(unsafe.Pointer(&output[oOff+d:][0]))
		}
		for ; d < headDim; d++ {
			var sum float32
			for j := range kvLen {
				sum += scores[sOff+j].Float32() * v[j*headDim+d].Float32()
			}
			output[oOff+d] = hwy.Float32ToBFloat16(sum)
		}
	}
}

func BaseSDPA_avx2(q []float32, k []float32, v []float32, mask []float32, scores []float32, output []float32, seqLen int, kvLen int, headDim int, scale float32) {
	if seqLen == 0 || kvLen == 0 || headDim == 0 {
		return
	}
	lanes := 8
	for i := range seqLen {
		qOff := i * headDim
		sOff := i * kvLen
		j := 0
		for ; j+4 <= kvLen; j += 4 {
			acc0 := archsimd.BroadcastFloat32x8(0)
			acc1 := archsimd.BroadcastFloat32x8(0)
			acc2 := archsimd.BroadcastFloat32x8(0)
			acc3 := archsimd.BroadcastFloat32x8(0)
			kOff0 := j * headDim
			kOff1 := (j + 1) * headDim
			kOff2 := (j + 2) * headDim
			kOff3 := (j + 3) * headDim
			p := 0
			for ; p+lanes <= headDim; p += lanes {
				vQ := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&q[qOff+p])))
				acc0 = vQ.MulAdd(archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&k[kOff0+p]))), acc0)
				acc1 = vQ.MulAdd(archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&k[kOff1+p]))), acc1)
				acc2 = vQ.MulAdd(archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&k[kOff2+p]))), acc2)
				acc3 = vQ.MulAdd(archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&k[kOff3+p]))), acc3)
			}
			s0 := hwy.ReduceSum_AVX2_F32x8(acc0)
			s1 := hwy.ReduceSum_AVX2_F32x8(acc1)
			s2 := hwy.ReduceSum_AVX2_F32x8(acc2)
			s3 := hwy.ReduceSum_AVX2_F32x8(acc3)
			for ; p < headDim; p++ {
				qp := q[qOff+p]
				s0 += qp * k[kOff0+p]
				s1 += qp * k[kOff1+p]
				s2 += qp * k[kOff2+p]
				s3 += qp * k[kOff3+p]
			}
			scores[sOff+j] = s0 * scale
			scores[sOff+j+1] = s1 * scale
			scores[sOff+j+2] = s2 * scale
			scores[sOff+j+3] = s3 * scale
		}
		for ; j < kvLen; j++ {
			kOff := j * headDim
			acc := archsimd.BroadcastFloat32x8(0)
			p := 0
			for ; p+lanes <= headDim; p += lanes {
				vQ := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&q[qOff+p])))
				vK := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&k[kOff+p])))
				acc = vQ.MulAdd(vK, acc)
			}
			sum := hwy.ReduceSum_AVX2_F32x8(acc)
			for ; p < headDim; p++ {
				sum += q[qOff+p] * k[kOff+p]
			}
			scores[sOff+j] = sum * scale
		}
		if mask != nil {
			mOff := i * kvLen
			si := 0
			for ; si+lanes <= kvLen; si += lanes {
				s := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&scores[sOff+si])))
				m := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&mask[mOff+si])))
				s.Add(m).Store((*[8]float32)(unsafe.Pointer(&scores[sOff+si])))
			}
			for ; si < kvLen; si++ {
				scores[sOff+si] += mask[mOff+si]
			}
		}
		maxVal := scores[sOff]
		for j := 1; j < kvLen; j++ {
			if scores[sOff+j] > maxVal {
				maxVal = scores[sOff+j]
			}
		}
		vMax := archsimd.BroadcastFloat32x8(maxVal)
		sumAcc := archsimd.BroadcastFloat32x8(0)
		si := 0
		for ; si+lanes <= kvLen; si += lanes {
			x := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&scores[sOff+si])))
			shifted := x.Sub(vMax)
			expVal := math.BaseExpVec_avx2(shifted)
			expVal.Store((*[8]float32)(unsafe.Pointer(&scores[sOff+si])))
			sumAcc = sumAcc.Add(expVal)
		}
		expSum := hwy.ReduceSum_AVX2_F32x8(sumAcc)
		for ; si < kvLen; si++ {
			scores[sOff+si] = float32(stdmath.Exp(float64(scores[sOff+si] - maxVal)))
			expSum += scores[sOff+si]
		}
		invSum := float32(1.0) / expSum
		vInvSum := archsimd.BroadcastFloat32x8(invSum)
		si = 0
		for ; si+lanes <= kvLen; si += lanes {
			x := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&scores[sOff+si])))
			x.Mul(vInvSum).Store((*[8]float32)(unsafe.Pointer(&scores[sOff+si])))
		}
		for ; si < kvLen; si++ {
			scores[sOff+si] = scores[sOff+si] * invSum
		}
		oOff := i * headDim
		tileD := 4 * lanes
		d := 0
		for ; d+tileD <= headDim; d += tileD {
			acc0 := archsimd.BroadcastFloat32x8(0)
			acc1 := archsimd.BroadcastFloat32x8(0)
			acc2 := archsimd.BroadcastFloat32x8(0)
			acc3 := archsimd.BroadcastFloat32x8(0)
			for j := range kvLen {
				vS := archsimd.BroadcastFloat32x8(scores[sOff+j])
				vRow := v[j*headDim:]
				acc0 = vS.MulAdd(archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&vRow[d]))), acc0)
				acc1 = vS.MulAdd(archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&vRow[d+lanes]))), acc1)
				acc2 = vS.MulAdd(archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&vRow[d+2*lanes]))), acc2)
				acc3 = vS.MulAdd(archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&vRow[d+3*lanes]))), acc3)
			}
			acc0.Store((*[8]float32)(unsafe.Pointer(&output[oOff+d])))
			acc1.Store((*[8]float32)(unsafe.Pointer(&output[oOff+d+lanes])))
			acc2.Store((*[8]float32)(unsafe.Pointer(&output[oOff+d+2*lanes])))
			acc3.Store((*[8]float32)(unsafe.Pointer(&output[oOff+d+3*lanes])))
		}
		for ; d+lanes <= headDim; d += lanes {
			acc := archsimd.BroadcastFloat32x8(0)
			for j := range kvLen {
				vS := archsimd.BroadcastFloat32x8(scores[sOff+j])
				acc = vS.MulAdd(archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&v[j*headDim+d]))), acc)
			}
			acc.Store((*[8]float32)(unsafe.Pointer(&output[oOff+d])))
		}
		for ; d < headDim; d++ {
			var sum float32
			for j := range kvLen {
				sum += scores[sOff+j] * v[j*headDim+d]
			}
			output[oOff+d] = sum
		}
	}
}

func BaseSDPA_avx2_Float64(q []float64, k []float64, v []float64, mask []float64, scores []float64, output []float64, seqLen int, kvLen int, headDim int, scale float64) {
	if seqLen == 0 || kvLen == 0 || headDim == 0 {
		return
	}
	lanes := 4
	for i := range seqLen {
		qOff := i * headDim
		sOff := i * kvLen
		j := 0
		for ; j+4 <= kvLen; j += 4 {
			acc0 := archsimd.BroadcastFloat64x4(0)
			acc1 := archsimd.BroadcastFloat64x4(0)
			acc2 := archsimd.BroadcastFloat64x4(0)
			acc3 := archsimd.BroadcastFloat64x4(0)
			kOff0 := j * headDim
			kOff1 := (j + 1) * headDim
			kOff2 := (j + 2) * headDim
			kOff3 := (j + 3) * headDim
			p := 0
			for ; p+lanes <= headDim; p += lanes {
				vQ := archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&q[qOff+p])))
				acc0 = vQ.MulAdd(archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&k[kOff0+p]))), acc0)
				acc1 = vQ.MulAdd(archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&k[kOff1+p]))), acc1)
				acc2 = vQ.MulAdd(archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&k[kOff2+p]))), acc2)
				acc3 = vQ.MulAdd(archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&k[kOff3+p]))), acc3)
			}
			s0 := hwy.ReduceSum_AVX2_F64x4(acc0)
			s1 := hwy.ReduceSum_AVX2_F64x4(acc1)
			s2 := hwy.ReduceSum_AVX2_F64x4(acc2)
			s3 := hwy.ReduceSum_AVX2_F64x4(acc3)
			for ; p < headDim; p++ {
				qp := q[qOff+p]
				s0 += qp * k[kOff0+p]
				s1 += qp * k[kOff1+p]
				s2 += qp * k[kOff2+p]
				s3 += qp * k[kOff3+p]
			}
			scores[sOff+j] = s0 * scale
			scores[sOff+j+1] = s1 * scale
			scores[sOff+j+2] = s2 * scale
			scores[sOff+j+3] = s3 * scale
		}
		for ; j < kvLen; j++ {
			kOff := j * headDim
			acc := archsimd.BroadcastFloat64x4(0)
			p := 0
			for ; p+lanes <= headDim; p += lanes {
				vQ := archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&q[qOff+p])))
				vK := archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&k[kOff+p])))
				acc = vQ.MulAdd(vK, acc)
			}
			sum := hwy.ReduceSum_AVX2_F64x4(acc)
			for ; p < headDim; p++ {
				sum += q[qOff+p] * k[kOff+p]
			}
			scores[sOff+j] = sum * scale
		}
		if mask != nil {
			mOff := i * kvLen
			si := 0
			for ; si+lanes <= kvLen; si += lanes {
				s := archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&scores[sOff+si])))
				m := archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&mask[mOff+si])))
				s.Add(m).Store((*[4]float64)(unsafe.Pointer(&scores[sOff+si])))
			}
			for ; si < kvLen; si++ {
				scores[sOff+si] += mask[mOff+si]
			}
		}
		maxVal := scores[sOff]
		for j := 1; j < kvLen; j++ {
			if scores[sOff+j] > maxVal {
				maxVal = scores[sOff+j]
			}
		}
		vMax := archsimd.BroadcastFloat64x4(maxVal)
		sumAcc := archsimd.BroadcastFloat64x4(0)
		si := 0
		for ; si+lanes <= kvLen; si += lanes {
			x := archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&scores[sOff+si])))
			shifted := x.Sub(vMax)
			expVal := math.BaseExpVec_avx2_Float64(shifted)
			expVal.Store((*[4]float64)(unsafe.Pointer(&scores[sOff+si])))
			sumAcc = sumAcc.Add(expVal)
		}
		expSum := hwy.ReduceSum_AVX2_F64x4(sumAcc)
		for ; si < kvLen; si++ {
			scores[sOff+si] = float64(stdmath.Exp(float64(scores[sOff+si] - maxVal)))
			expSum += scores[sOff+si]
		}
		invSum := float64(1.0) / expSum
		vInvSum := archsimd.BroadcastFloat64x4(invSum)
		si = 0
		for ; si+lanes <= kvLen; si += lanes {
			x := archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&scores[sOff+si])))
			x.Mul(vInvSum).Store((*[4]float64)(unsafe.Pointer(&scores[sOff+si])))
		}
		for ; si < kvLen; si++ {
			scores[sOff+si] = scores[sOff+si] * invSum
		}
		oOff := i * headDim
		tileD := 4 * lanes
		d := 0
		for ; d+tileD <= headDim; d += tileD {
			acc0 := archsimd.BroadcastFloat64x4(0)
			acc1 := archsimd.BroadcastFloat64x4(0)
			acc2 := archsimd.BroadcastFloat64x4(0)
			acc3 := archsimd.BroadcastFloat64x4(0)
			for j := range kvLen {
				vS := archsimd.BroadcastFloat64x4(scores[sOff+j])
				vRow := v[j*headDim:]
				acc0 = vS.MulAdd(archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&vRow[d]))), acc0)
				acc1 = vS.MulAdd(archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&vRow[d+lanes]))), acc1)
				acc2 = vS.MulAdd(archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&vRow[d+2*lanes]))), acc2)
				acc3 = vS.MulAdd(archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&vRow[d+3*lanes]))), acc3)
			}
			acc0.Store((*[4]float64)(unsafe.Pointer(&output[oOff+d])))
			acc1.Store((*[4]float64)(unsafe.Pointer(&output[oOff+d+lanes])))
			acc2.Store((*[4]float64)(unsafe.Pointer(&output[oOff+d+2*lanes])))
			acc3.Store((*[4]float64)(unsafe.Pointer(&output[oOff+d+3*lanes])))
		}
		for ; d+lanes <= headDim; d += lanes {
			acc := archsimd.BroadcastFloat64x4(0)
			for j := range kvLen {
				vS := archsimd.BroadcastFloat64x4(scores[sOff+j])
				acc = vS.MulAdd(archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&v[j*headDim+d]))), acc)
			}
			acc.Store((*[4]float64)(unsafe.Pointer(&output[oOff+d])))
		}
		for ; d < headDim; d++ {
			var sum float64
			for j := range kvLen {
				sum += scores[sOff+j] * v[j*headDim+d]
			}
			output[oOff+d] = sum
		}
	}
}

func BaseSDPACausal_avx2_Float16(q []hwy.Float16, k []hwy.Float16, v []hwy.Float16, scores []hwy.Float16, output []hwy.Float16, seqLen int, kvLen int, headDim int, scale hwy.Float16) {
	if seqLen == 0 || kvLen == 0 || headDim == 0 {
		return
	}
	lanes := 8
	negInf := hwy.Float32ToFloat16(float32(stdmath.Inf(-1)))
	offset := kvLen - seqLen
	for i := range seqLen {
		qOff := i * headDim
		sOff := i * kvLen
		causalEnd := i + offset + 1
		j := 0
		for ; j+4 <= kvLen && j+4 <= causalEnd; j += 4 {
			acc0 := asm.ZeroFloat16x8AVX2()
			acc1 := asm.ZeroFloat16x8AVX2()
			acc2 := asm.ZeroFloat16x8AVX2()
			acc3 := asm.ZeroFloat16x8AVX2()
			kOff0 := j * headDim
			kOff1 := (j + 1) * headDim
			kOff2 := (j + 2) * headDim
			kOff3 := (j + 3) * headDim
			p := 0
			for ; p+lanes <= headDim; p += lanes {
				vQ := asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&q[qOff+p:][0]))
				acc0 = vQ.MulAdd(asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&k[kOff0+p:][0])), acc0)
				acc1 = vQ.MulAdd(asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&k[kOff1+p:][0])), acc1)
				acc2 = vQ.MulAdd(asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&k[kOff2+p:][0])), acc2)
				acc3 = vQ.MulAdd(asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&k[kOff3+p:][0])), acc3)
			}
			s0 := acc0.ReduceSum()
			s1 := acc1.ReduceSum()
			s2 := acc2.ReduceSum()
			s3 := acc3.ReduceSum()
			for ; p < headDim; p++ {
				qp := q[qOff+p]
				s0 += qp.Float32() * k[kOff0+p].Float32()
				s1 += qp.Float32() * k[kOff1+p].Float32()
				s2 += qp.Float32() * k[kOff2+p].Float32()
				s3 += qp.Float32() * k[kOff3+p].Float32()
			}
			scores[sOff+j] = hwy.Float32ToFloat16(s0 * scale.Float32())
			scores[sOff+j+1] = hwy.Float32ToFloat16(s1 * scale.Float32())
			scores[sOff+j+2] = hwy.Float32ToFloat16(s2 * scale.Float32())
			scores[sOff+j+3] = hwy.Float32ToFloat16(s3 * scale.Float32())
		}
		for ; j < kvLen; j++ {
			if j >= causalEnd {
				scores[sOff+j] = hwy.Float32ToFloat16(negInf.Float32())
				continue
			}
			kOff := j * headDim
			acc := asm.ZeroFloat16x8AVX2()
			p := 0
			for ; p+lanes <= headDim; p += lanes {
				vQ := asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&q[qOff+p:][0]))
				vK := asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&k[kOff+p:][0]))
				acc = vQ.MulAdd(vK, acc)
			}
			sum := acc.ReduceSum()
			for ; p < headDim; p++ {
				sum += q[qOff+p].Float32() * k[kOff+p].Float32()
			}
			scores[sOff+j] = hwy.Float32ToFloat16(sum * scale.Float32())
		}
		maxVal := scores[sOff]
		for j := 1; j < kvLen; j++ {
			if scores[sOff+j].Float32() > maxVal.Float32() {
				maxVal = scores[sOff+j]
			}
		}
		vMax := asm.BroadcastFloat16x8AVX2(uint16(maxVal))
		sumAcc := asm.ZeroFloat16x8AVX2()
		si := 0
		for ; si+lanes <= kvLen; si += lanes {
			x := asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&scores[sOff+si:][0]))
			shifted := x.Sub(vMax)
			expVal := math.BaseExpVec_avx2_Float16(shifted)
			expVal.StorePtr(unsafe.Pointer(&scores[sOff+si:][0]))
			sumAcc = sumAcc.Add(expVal)
		}
		expSum := sumAcc.ReduceSum()
		for ; si < kvLen; si++ {
			scores[sOff+si] = hwy.Float32ToFloat16(float32(stdmath.Exp(float64(scores[sOff+si].Float32() - maxVal.Float32()))))
			expSum += scores[sOff+si].Float32()
		}
		invSum := hwy.Float32ToFloat16(float32(1.0) / expSum)
		vInvSum := asm.BroadcastFloat16x8AVX2(uint16(invSum))
		si = 0
		for ; si+lanes <= kvLen; si += lanes {
			x := asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&scores[sOff+si:][0]))
			x.Mul(vInvSum).StorePtr(unsafe.Pointer(&scores[sOff+si:][0]))
		}
		for ; si < kvLen; si++ {
			scores[sOff+si] = hwy.Float32ToFloat16(scores[sOff+si].Float32() * invSum.Float32())
		}
		oOff := i * headDim
		tileD := 4 * lanes
		d := 0
		for ; d+tileD <= headDim; d += tileD {
			acc0 := asm.ZeroFloat16x8AVX2()
			acc1 := asm.ZeroFloat16x8AVX2()
			acc2 := asm.ZeroFloat16x8AVX2()
			acc3 := asm.ZeroFloat16x8AVX2()
			for j := range kvLen {
				vS := asm.BroadcastFloat16x8AVX2(uint16(scores[sOff+j]))
				vRow := v[j*headDim:]
				acc0 = vS.MulAdd(asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&vRow[d:][0])), acc0)
				acc1 = vS.MulAdd(asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&vRow[d+lanes:][0])), acc1)
				acc2 = vS.MulAdd(asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&vRow[d+2*lanes:][0])), acc2)
				acc3 = vS.MulAdd(asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&vRow[d+3*lanes:][0])), acc3)
			}
			acc0.StorePtr(unsafe.Pointer(&output[oOff+d:][0]))
			acc1.StorePtr(unsafe.Pointer(&output[oOff+d+lanes:][0]))
			acc2.StorePtr(unsafe.Pointer(&output[oOff+d+2*lanes:][0]))
			acc3.StorePtr(unsafe.Pointer(&output[oOff+d+3*lanes:][0]))
		}
		for ; d+lanes <= headDim; d += lanes {
			acc := asm.ZeroFloat16x8AVX2()
			for j := range kvLen {
				vS := asm.BroadcastFloat16x8AVX2(uint16(scores[sOff+j]))
				acc = vS.MulAdd(asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&v[j*headDim+d:][0])), acc)
			}
			acc.StorePtr(unsafe.Pointer(&output[oOff+d:][0]))
		}
		for ; d < headDim; d++ {
			var sum float32
			for j := range kvLen {
				sum += scores[sOff+j].Float32() * v[j*headDim+d].Float32()
			}
			output[oOff+d] = hwy.Float32ToFloat16(sum)
		}
	}
}

func BaseSDPACausal_avx2_BFloat16(q []hwy.BFloat16, k []hwy.BFloat16, v []hwy.BFloat16, scores []hwy.BFloat16, output []hwy.BFloat16, seqLen int, kvLen int, headDim int, scale hwy.BFloat16) {
	if seqLen == 0 || kvLen == 0 || headDim == 0 {
		return
	}
	lanes := 8
	negInf := hwy.Float32ToBFloat16(float32(stdmath.Inf(-1)))
	offset := kvLen - seqLen
	for i := range seqLen {
		qOff := i * headDim
		sOff := i * kvLen
		causalEnd := i + offset + 1
		j := 0
		for ; j+4 <= kvLen && j+4 <= causalEnd; j += 4 {
			acc0 := asm.ZeroBFloat16x8AVX2()
			acc1 := asm.ZeroBFloat16x8AVX2()
			acc2 := asm.ZeroBFloat16x8AVX2()
			acc3 := asm.ZeroBFloat16x8AVX2()
			kOff0 := j * headDim
			kOff1 := (j + 1) * headDim
			kOff2 := (j + 2) * headDim
			kOff3 := (j + 3) * headDim
			p := 0
			for ; p+lanes <= headDim; p += lanes {
				vQ := asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&q[qOff+p:][0]))
				acc0 = vQ.MulAdd(asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&k[kOff0+p:][0])), acc0)
				acc1 = vQ.MulAdd(asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&k[kOff1+p:][0])), acc1)
				acc2 = vQ.MulAdd(asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&k[kOff2+p:][0])), acc2)
				acc3 = vQ.MulAdd(asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&k[kOff3+p:][0])), acc3)
			}
			s0 := acc0.ReduceSum()
			s1 := acc1.ReduceSum()
			s2 := acc2.ReduceSum()
			s3 := acc3.ReduceSum()
			for ; p < headDim; p++ {
				qp := q[qOff+p]
				s0 += qp.Float32() * k[kOff0+p].Float32()
				s1 += qp.Float32() * k[kOff1+p].Float32()
				s2 += qp.Float32() * k[kOff2+p].Float32()
				s3 += qp.Float32() * k[kOff3+p].Float32()
			}
			scores[sOff+j] = hwy.Float32ToBFloat16(s0 * scale.Float32())
			scores[sOff+j+1] = hwy.Float32ToBFloat16(s1 * scale.Float32())
			scores[sOff+j+2] = hwy.Float32ToBFloat16(s2 * scale.Float32())
			scores[sOff+j+3] = hwy.Float32ToBFloat16(s3 * scale.Float32())
		}
		for ; j < kvLen; j++ {
			if j >= causalEnd {
				scores[sOff+j] = hwy.Float32ToBFloat16(negInf.Float32())
				continue
			}
			kOff := j * headDim
			acc := asm.ZeroBFloat16x8AVX2()
			p := 0
			for ; p+lanes <= headDim; p += lanes {
				vQ := asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&q[qOff+p:][0]))
				vK := asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&k[kOff+p:][0]))
				acc = vQ.MulAdd(vK, acc)
			}
			sum := acc.ReduceSum()
			for ; p < headDim; p++ {
				sum += q[qOff+p].Float32() * k[kOff+p].Float32()
			}
			scores[sOff+j] = hwy.Float32ToBFloat16(sum * scale.Float32())
		}
		maxVal := scores[sOff]
		for j := 1; j < kvLen; j++ {
			if scores[sOff+j].Float32() > maxVal.Float32() {
				maxVal = scores[sOff+j]
			}
		}
		vMax := asm.BroadcastBFloat16x8AVX2(uint16(maxVal))
		sumAcc := asm.ZeroBFloat16x8AVX2()
		si := 0
		for ; si+lanes <= kvLen; si += lanes {
			x := asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&scores[sOff+si:][0]))
			shifted := x.Sub(vMax)
			expVal := math.BaseExpVec_avx2_BFloat16(shifted)
			expVal.StorePtr(unsafe.Pointer(&scores[sOff+si:][0]))
			sumAcc = sumAcc.Add(expVal)
		}
		expSum := sumAcc.ReduceSum()
		for ; si < kvLen; si++ {
			scores[sOff+si] = hwy.Float32ToBFloat16(float32(stdmath.Exp(float64(scores[sOff+si].Float32() - maxVal.Float32()))))
			expSum += scores[sOff+si].Float32()
		}
		invSum := hwy.Float32ToBFloat16(float32(1.0) / expSum)
		vInvSum := asm.BroadcastBFloat16x8AVX2(uint16(invSum))
		si = 0
		for ; si+lanes <= kvLen; si += lanes {
			x := asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&scores[sOff+si:][0]))
			x.Mul(vInvSum).StorePtr(unsafe.Pointer(&scores[sOff+si:][0]))
		}
		for ; si < kvLen; si++ {
			scores[sOff+si] = hwy.Float32ToBFloat16(scores[sOff+si].Float32() * invSum.Float32())
		}
		oOff := i * headDim
		tileD := 4 * lanes
		d := 0
		for ; d+tileD <= headDim; d += tileD {
			acc0 := asm.ZeroBFloat16x8AVX2()
			acc1 := asm.ZeroBFloat16x8AVX2()
			acc2 := asm.ZeroBFloat16x8AVX2()
			acc3 := asm.ZeroBFloat16x8AVX2()
			for j := range kvLen {
				vS := asm.BroadcastBFloat16x8AVX2(uint16(scores[sOff+j]))
				vRow := v[j*headDim:]
				acc0 = vS.MulAdd(asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&vRow[d:][0])), acc0)
				acc1 = vS.MulAdd(asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&vRow[d+lanes:][0])), acc1)
				acc2 = vS.MulAdd(asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&vRow[d+2*lanes:][0])), acc2)
				acc3 = vS.MulAdd(asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&vRow[d+3*lanes:][0])), acc3)
			}
			acc0.StorePtr(unsafe.Pointer(&output[oOff+d:][0]))
			acc1.StorePtr(unsafe.Pointer(&output[oOff+d+lanes:][0]))
			acc2.StorePtr(unsafe.Pointer(&output[oOff+d+2*lanes:][0]))
			acc3.StorePtr(unsafe.Pointer(&output[oOff+d+3*lanes:][0]))
		}
		for ; d+lanes <= headDim; d += lanes {
			acc := asm.ZeroBFloat16x8AVX2()
			for j := range kvLen {
				vS := asm.BroadcastBFloat16x8AVX2(uint16(scores[sOff+j]))
				acc = vS.MulAdd(asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&v[j*headDim+d:][0])), acc)
			}
			acc.StorePtr(unsafe.Pointer(&output[oOff+d:][0]))
		}
		for ; d < headDim; d++ {
			var sum float32
			for j := range kvLen {
				sum += scores[sOff+j].Float32() * v[j*headDim+d].Float32()
			}
			output[oOff+d] = hwy.Float32ToBFloat16(sum)
		}
	}
}

func BaseSDPACausal_avx2(q []float32, k []float32, v []float32, scores []float32, output []float32, seqLen int, kvLen int, headDim int, scale float32) {
	if seqLen == 0 || kvLen == 0 || headDim == 0 {
		return
	}
	lanes := 8
	negInf := float32(stdmath.Inf(-1))
	offset := kvLen - seqLen
	for i := range seqLen {
		qOff := i * headDim
		sOff := i * kvLen
		causalEnd := i + offset + 1
		j := 0
		for ; j+4 <= kvLen && j+4 <= causalEnd; j += 4 {
			acc0 := archsimd.BroadcastFloat32x8(0)
			acc1 := archsimd.BroadcastFloat32x8(0)
			acc2 := archsimd.BroadcastFloat32x8(0)
			acc3 := archsimd.BroadcastFloat32x8(0)
			kOff0 := j * headDim
			kOff1 := (j + 1) * headDim
			kOff2 := (j + 2) * headDim
			kOff3 := (j + 3) * headDim
			p := 0
			for ; p+lanes <= headDim; p += lanes {
				vQ := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&q[qOff+p])))
				acc0 = vQ.MulAdd(archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&k[kOff0+p]))), acc0)
				acc1 = vQ.MulAdd(archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&k[kOff1+p]))), acc1)
				acc2 = vQ.MulAdd(archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&k[kOff2+p]))), acc2)
				acc3 = vQ.MulAdd(archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&k[kOff3+p]))), acc3)
			}
			s0 := hwy.ReduceSum_AVX2_F32x8(acc0)
			s1 := hwy.ReduceSum_AVX2_F32x8(acc1)
			s2 := hwy.ReduceSum_AVX2_F32x8(acc2)
			s3 := hwy.ReduceSum_AVX2_F32x8(acc3)
			for ; p < headDim; p++ {
				qp := q[qOff+p]
				s0 += qp * k[kOff0+p]
				s1 += qp * k[kOff1+p]
				s2 += qp * k[kOff2+p]
				s3 += qp * k[kOff3+p]
			}
			scores[sOff+j] = s0 * scale
			scores[sOff+j+1] = s1 * scale
			scores[sOff+j+2] = s2 * scale
			scores[sOff+j+3] = s3 * scale
		}
		for ; j < kvLen; j++ {
			if j >= causalEnd {
				scores[sOff+j] = negInf
				continue
			}
			kOff := j * headDim
			acc := archsimd.BroadcastFloat32x8(0)
			p := 0
			for ; p+lanes <= headDim; p += lanes {
				vQ := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&q[qOff+p])))
				vK := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&k[kOff+p])))
				acc = vQ.MulAdd(vK, acc)
			}
			sum := hwy.ReduceSum_AVX2_F32x8(acc)
			for ; p < headDim; p++ {
				sum += q[qOff+p] * k[kOff+p]
			}
			scores[sOff+j] = sum * scale
		}
		maxVal := scores[sOff]
		for j := 1; j < kvLen; j++ {
			if scores[sOff+j] > maxVal {
				maxVal = scores[sOff+j]
			}
		}
		vMax := archsimd.BroadcastFloat32x8(maxVal)
		sumAcc := archsimd.BroadcastFloat32x8(0)
		si := 0
		for ; si+lanes <= kvLen; si += lanes {
			x := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&scores[sOff+si])))
			shifted := x.Sub(vMax)
			expVal := math.BaseExpVec_avx2(shifted)
			expVal.Store((*[8]float32)(unsafe.Pointer(&scores[sOff+si])))
			sumAcc = sumAcc.Add(expVal)
		}
		expSum := hwy.ReduceSum_AVX2_F32x8(sumAcc)
		for ; si < kvLen; si++ {
			scores[sOff+si] = float32(stdmath.Exp(float64(scores[sOff+si] - maxVal)))
			expSum += scores[sOff+si]
		}
		invSum := float32(1.0) / expSum
		vInvSum := archsimd.BroadcastFloat32x8(invSum)
		si = 0
		for ; si+lanes <= kvLen; si += lanes {
			x := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&scores[sOff+si])))
			x.Mul(vInvSum).Store((*[8]float32)(unsafe.Pointer(&scores[sOff+si])))
		}
		for ; si < kvLen; si++ {
			scores[sOff+si] = scores[sOff+si] * invSum
		}
		oOff := i * headDim
		tileD := 4 * lanes
		d := 0
		for ; d+tileD <= headDim; d += tileD {
			acc0 := archsimd.BroadcastFloat32x8(0)
			acc1 := archsimd.BroadcastFloat32x8(0)
			acc2 := archsimd.BroadcastFloat32x8(0)
			acc3 := archsimd.BroadcastFloat32x8(0)
			for j := range kvLen {
				vS := archsimd.BroadcastFloat32x8(scores[sOff+j])
				vRow := v[j*headDim:]
				acc0 = vS.MulAdd(archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&vRow[d]))), acc0)
				acc1 = vS.MulAdd(archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&vRow[d+lanes]))), acc1)
				acc2 = vS.MulAdd(archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&vRow[d+2*lanes]))), acc2)
				acc3 = vS.MulAdd(archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&vRow[d+3*lanes]))), acc3)
			}
			acc0.Store((*[8]float32)(unsafe.Pointer(&output[oOff+d])))
			acc1.Store((*[8]float32)(unsafe.Pointer(&output[oOff+d+lanes])))
			acc2.Store((*[8]float32)(unsafe.Pointer(&output[oOff+d+2*lanes])))
			acc3.Store((*[8]float32)(unsafe.Pointer(&output[oOff+d+3*lanes])))
		}
		for ; d+lanes <= headDim; d += lanes {
			acc := archsimd.BroadcastFloat32x8(0)
			for j := range kvLen {
				vS := archsimd.BroadcastFloat32x8(scores[sOff+j])
				acc = vS.MulAdd(archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&v[j*headDim+d]))), acc)
			}
			acc.Store((*[8]float32)(unsafe.Pointer(&output[oOff+d])))
		}
		for ; d < headDim; d++ {
			var sum float32
			for j := range kvLen {
				sum += scores[sOff+j] * v[j*headDim+d]
			}
			output[oOff+d] = sum
		}
	}
}

func BaseSDPACausal_avx2_Float64(q []float64, k []float64, v []float64, scores []float64, output []float64, seqLen int, kvLen int, headDim int, scale float64) {
	if seqLen == 0 || kvLen == 0 || headDim == 0 {
		return
	}
	lanes := 4
	negInf := float64(stdmath.Inf(-1))
	offset := kvLen - seqLen
	for i := range seqLen {
		qOff := i * headDim
		sOff := i * kvLen
		causalEnd := i + offset + 1
		j := 0
		for ; j+4 <= kvLen && j+4 <= causalEnd; j += 4 {
			acc0 := archsimd.BroadcastFloat64x4(0)
			acc1 := archsimd.BroadcastFloat64x4(0)
			acc2 := archsimd.BroadcastFloat64x4(0)
			acc3 := archsimd.BroadcastFloat64x4(0)
			kOff0 := j * headDim
			kOff1 := (j + 1) * headDim
			kOff2 := (j + 2) * headDim
			kOff3 := (j + 3) * headDim
			p := 0
			for ; p+lanes <= headDim; p += lanes {
				vQ := archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&q[qOff+p])))
				acc0 = vQ.MulAdd(archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&k[kOff0+p]))), acc0)
				acc1 = vQ.MulAdd(archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&k[kOff1+p]))), acc1)
				acc2 = vQ.MulAdd(archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&k[kOff2+p]))), acc2)
				acc3 = vQ.MulAdd(archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&k[kOff3+p]))), acc3)
			}
			s0 := hwy.ReduceSum_AVX2_F64x4(acc0)
			s1 := hwy.ReduceSum_AVX2_F64x4(acc1)
			s2 := hwy.ReduceSum_AVX2_F64x4(acc2)
			s3 := hwy.ReduceSum_AVX2_F64x4(acc3)
			for ; p < headDim; p++ {
				qp := q[qOff+p]
				s0 += qp * k[kOff0+p]
				s1 += qp * k[kOff1+p]
				s2 += qp * k[kOff2+p]
				s3 += qp * k[kOff3+p]
			}
			scores[sOff+j] = s0 * scale
			scores[sOff+j+1] = s1 * scale
			scores[sOff+j+2] = s2 * scale
			scores[sOff+j+3] = s3 * scale
		}
		for ; j < kvLen; j++ {
			if j >= causalEnd {
				scores[sOff+j] = negInf
				continue
			}
			kOff := j * headDim
			acc := archsimd.BroadcastFloat64x4(0)
			p := 0
			for ; p+lanes <= headDim; p += lanes {
				vQ := archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&q[qOff+p])))
				vK := archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&k[kOff+p])))
				acc = vQ.MulAdd(vK, acc)
			}
			sum := hwy.ReduceSum_AVX2_F64x4(acc)
			for ; p < headDim; p++ {
				sum += q[qOff+p] * k[kOff+p]
			}
			scores[sOff+j] = sum * scale
		}
		maxVal := scores[sOff]
		for j := 1; j < kvLen; j++ {
			if scores[sOff+j] > maxVal {
				maxVal = scores[sOff+j]
			}
		}
		vMax := archsimd.BroadcastFloat64x4(maxVal)
		sumAcc := archsimd.BroadcastFloat64x4(0)
		si := 0
		for ; si+lanes <= kvLen; si += lanes {
			x := archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&scores[sOff+si])))
			shifted := x.Sub(vMax)
			expVal := math.BaseExpVec_avx2_Float64(shifted)
			expVal.Store((*[4]float64)(unsafe.Pointer(&scores[sOff+si])))
			sumAcc = sumAcc.Add(expVal)
		}
		expSum := hwy.ReduceSum_AVX2_F64x4(sumAcc)
		for ; si < kvLen; si++ {
			scores[sOff+si] = float64(stdmath.Exp(float64(scores[sOff+si] - maxVal)))
			expSum += scores[sOff+si]
		}
		invSum := float64(1.0) / expSum
		vInvSum := archsimd.BroadcastFloat64x4(invSum)
		si = 0
		for ; si+lanes <= kvLen; si += lanes {
			x := archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&scores[sOff+si])))
			x.Mul(vInvSum).Store((*[4]float64)(unsafe.Pointer(&scores[sOff+si])))
		}
		for ; si < kvLen; si++ {
			scores[sOff+si] = scores[sOff+si] * invSum
		}
		oOff := i * headDim
		tileD := 4 * lanes
		d := 0
		for ; d+tileD <= headDim; d += tileD {
			acc0 := archsimd.BroadcastFloat64x4(0)
			acc1 := archsimd.BroadcastFloat64x4(0)
			acc2 := archsimd.BroadcastFloat64x4(0)
			acc3 := archsimd.BroadcastFloat64x4(0)
			for j := range kvLen {
				vS := archsimd.BroadcastFloat64x4(scores[sOff+j])
				vRow := v[j*headDim:]
				acc0 = vS.MulAdd(archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&vRow[d]))), acc0)
				acc1 = vS.MulAdd(archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&vRow[d+lanes]))), acc1)
				acc2 = vS.MulAdd(archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&vRow[d+2*lanes]))), acc2)
				acc3 = vS.MulAdd(archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&vRow[d+3*lanes]))), acc3)
			}
			acc0.Store((*[4]float64)(unsafe.Pointer(&output[oOff+d])))
			acc1.Store((*[4]float64)(unsafe.Pointer(&output[oOff+d+lanes])))
			acc2.Store((*[4]float64)(unsafe.Pointer(&output[oOff+d+2*lanes])))
			acc3.Store((*[4]float64)(unsafe.Pointer(&output[oOff+d+3*lanes])))
		}
		for ; d+lanes <= headDim; d += lanes {
			acc := archsimd.BroadcastFloat64x4(0)
			for j := range kvLen {
				vS := archsimd.BroadcastFloat64x4(scores[sOff+j])
				acc = vS.MulAdd(archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&v[j*headDim+d]))), acc)
			}
			acc.Store((*[4]float64)(unsafe.Pointer(&output[oOff+d])))
		}
		for ; d < headDim; d++ {
			var sum float64
			for j := range kvLen {
				sum += scores[sOff+j] * v[j*headDim+d]
			}
			output[oOff+d] = sum
		}
	}
}
