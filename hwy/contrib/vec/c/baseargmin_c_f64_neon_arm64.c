// Generated by hwygen -c (AST translator). DO NOT EDIT.
// BaseArgmin for NEON float64

#ifndef GOAT_PARSER
#include <arm_neon.h>
#endif

#ifndef GOAT_PARSER
static inline float64x2_t _v_exp_f64(float64x2_t x) {
    float64x2_t invLn2 = vdupq_n_f64(1.4426950408889634);
    float64x2_t ln2Hi = vdupq_n_f64(6.93147180369123816490e-01);
    float64x2_t ln2Lo = vdupq_n_f64(1.90821492927058500170e-10);
    float64x2_t overflow = vdupq_n_f64(709.7827128933840);
    float64x2_t underflow = vdupq_n_f64(-708.3964185322641);
    float64x2_t one = vdupq_n_f64(1.0);
    float64x2_t zero = vdupq_n_f64(0.0);
    float64x2_t inf_val = vdupq_n_f64(1.0 / 0.0);
    uint64x2_t over = vcgtq_f64(x, overflow);
    uint64x2_t under = vcltq_f64(x, underflow);
    float64x2_t kf = vrndnq_f64(vmulq_f64(x, invLn2));
    float64x2_t r = vsubq_f64(x, vmulq_f64(kf, ln2Hi));
    r = vsubq_f64(r, vmulq_f64(kf, ln2Lo));
    /* Horner: p = c12*r + c11; p = p*r + c10; ... p = p*r + c2; p = p*r + 1; p = p*r + 1 */
    float64x2_t ep = vfmaq_f64(vdupq_n_f64(1.0/39916800.0), vdupq_n_f64(1.0/479001600.0), r);
    ep = vfmaq_f64(vdupq_n_f64(1.0/3628800.0), ep, r);
    ep = vfmaq_f64(vdupq_n_f64(1.0/362880.0), ep, r);
    ep = vfmaq_f64(vdupq_n_f64(1.0/40320.0), ep, r);
    ep = vfmaq_f64(vdupq_n_f64(1.0/5040.0), ep, r);
    ep = vfmaq_f64(vdupq_n_f64(1.0/720.0), ep, r);
    ep = vfmaq_f64(vdupq_n_f64(1.0/120.0), ep, r);
    ep = vfmaq_f64(vdupq_n_f64(1.0/24.0), ep, r);
    ep = vfmaq_f64(vdupq_n_f64(1.0/6.0), ep, r);
    ep = vfmaq_f64(vdupq_n_f64(0.5), ep, r);
    ep = vfmaq_f64(one, ep, r);
    ep = vfmaq_f64(one, ep, r);
    /* Construct 2^k: ((k + 1023) << 52) reinterpreted as double */
    int64x2_t ki = vcvtnq_s64_f64(kf);
    int64x2_t scale_bits = vshlq_n_s64(vaddq_s64(ki, vdupq_n_s64(1023)), 52);
    float64x2_t scale = vreinterpretq_f64_s64(scale_bits);
    float64x2_t result = vmulq_f64(ep, scale);
    result = vbslq_f64(over, inf_val, result);
    result = vbslq_f64(under, zero, result);
    return result;
}

static inline float64x2_t _v_sigmoid_f64(float64x2_t x) {
    float64x2_t one = vdupq_n_f64(1.0);
    float64x2_t exp_neg = _v_exp_f64(vnegq_f64(x));
    return vdivq_f64(one, vaddq_f64(one, exp_neg));
}

static inline float64x2_t _v_erf_f64(float64x2_t x) {
    float64x2_t zero = vdupq_n_f64(0.0);
    float64x2_t one = vdupq_n_f64(1.0);
    float64x2_t abs_x = vabsq_f64(x);
    uint64x2_t neg_mask = vcltq_f64(x, zero);
    float64x2_t sign = vbslq_f64(neg_mask, vdupq_n_f64(-1.0), one);
    float64x2_t t = vdivq_f64(one, vfmaq_f64(one, vdupq_n_f64(0.3275911), abs_x));
    float64x2_t t2 = vmulq_f64(t, t);
    float64x2_t t3 = vmulq_f64(t2, t);
    float64x2_t t4 = vmulq_f64(t3, t);
    float64x2_t t5 = vmulq_f64(t4, t);
    float64x2_t poly = vmulq_f64(vdupq_n_f64(0.254829592), t);
    poly = vfmaq_f64(poly, vdupq_n_f64(-0.284496736), t2);
    poly = vfmaq_f64(poly, vdupq_n_f64(1.421413741), t3);
    poly = vfmaq_f64(poly, vdupq_n_f64(-1.453152027), t4);
    poly = vfmaq_f64(poly, vdupq_n_f64(1.061405429), t5);
    float64x2_t exp_neg_x2 = _v_exp_f64(vnegq_f64(vmulq_f64(abs_x, abs_x)));
    float64x2_t result = vsubq_f64(one, vmulq_f64(poly, exp_neg_x2));
    return vmulq_f64(sign, result);
}

static inline double _s_exp_f64(double x) {
    if (x > 709.0) return 1.0 / 0.0;
    if (x < -709.0) return 0.0;
    double kf = __builtin_round(x * 1.4426950408889634);
    double r = x - kf * 6.93147180369123816490e-01;
    r = r - kf * 1.90821492927058500170e-10;
    double ep = (1.0/479001600.0) * r + (1.0/39916800.0);
    ep = ep * r + (1.0/3628800.0);
    ep = ep * r + (1.0/362880.0);
    ep = ep * r + (1.0/40320.0);
    ep = ep * r + (1.0/5040.0);
    ep = ep * r + (1.0/720.0);
    ep = ep * r + (1.0/120.0);
    ep = ep * r + (1.0/24.0);
    ep = ep * r + (1.0/6.0);
    ep = ep * r + 0.5;
    ep = ep * r + 1.0;
    ep = ep * r + 1.0;
    long ki = (long)kf;
    unsigned long bits = (unsigned long)(ki + 1023) << 52;
    double scale;
    __builtin_memcpy(&scale, &bits, 8);
    return ep * scale;
}

static inline double _s_sigmoid_f64(double x) {
    return 1.0 / (1.0 + _s_exp_f64(-x));
}

static inline double _s_erf_f64(double x) {
    double sign = 1.0;
    double ax = x;
    if (x < 0.0) { sign = -1.0; ax = -x; }
    double t = 1.0 / (1.0 + 0.3275911 * ax);
    double t2 = t * t;
    double t3 = t2 * t;
    double t4 = t3 * t;
    double t5 = t4 * t;
    double y = 1.0 - (0.254829592 * t - 0.284496736 * t2 +
        1.421413741 * t3 - 1.453152027 * t4 + 1.061405429 * t5) *
        _s_exp_f64(-ax * ax);
    return sign * y;
}

static inline float64x2_t _v_log_f64(float64x2_t x) {
    float64x2_t one = vdupq_n_f64(1.0);
    float64x2_t ln2 = vdupq_n_f64(0.6931471805599453);
    /* Extract exponent: e = ((bits >> 52) & 0x7FF) - 1023 */
    int64x2_t bits = vreinterpretq_s64_f64(x);
    int64x2_t exp_i = vsubq_s64(vandq_s64(vshrq_n_s64(bits, 52), vdupq_n_s64(0x7FF)), vdupq_n_s64(1023));
    float64x2_t e = vcvtq_f64_s64(exp_i);
    /* Normalize mantissa to [1,2) */
    int64x2_t m_bits = vorrq_s64(vandq_s64(bits, vdupq_n_s64(0x000FFFFFFFFFFFFF)), vdupq_n_s64(0x3FF0000000000000));
    float64x2_t m = vreinterpretq_f64_s64(m_bits);
    float64x2_t f = vsubq_f64(m, one);
    /* Higher-order minimax polynomial for log(1+f) in double */
    float64x2_t p = vdupq_n_f64(0.1484794514);
    p = vfmaq_f64(vdupq_n_f64(-0.1792383373), p, f);
    p = vfmaq_f64(vdupq_n_f64(0.2211827839), p, f);
    p = vfmaq_f64(vdupq_n_f64(-0.2857142857), p, f);
    p = vfmaq_f64(vdupq_n_f64(0.3999999999), p, f);
    p = vfmaq_f64(vdupq_n_f64(-0.4999999999), p, f);
    p = vfmaq_f64(vdupq_n_f64(0.9999999999), p, f);
    p = vmulq_f64(p, f);
    return vfmaq_f64(p, e, ln2);
}

static inline double _s_log_f64(double x) {
    unsigned long bits;
    __builtin_memcpy(&bits, &x, 8);
    long exp_i = (long)((bits >> 52) & 0x7FF) - 1023;
    double e = (double)exp_i;
    unsigned long m_bits = (bits & 0x000FFFFFFFFFFFFF) | 0x3FF0000000000000;
    double m;
    __builtin_memcpy(&m, &m_bits, 8);
    double f = m - 1.0;
    double p = 0.1484794514;
    p = p * f + -0.1792383373;
    p = p * f + 0.2211827839;
    p = p * f + -0.2857142857;
    p = p * f + 0.3999999999;
    p = p * f + -0.4999999999;
    p = p * f + 0.9999999999;
    p = p * f;
    return p + e * 0.6931471805599453;
}

static inline float64x2_t _v_pow_f64(float64x2_t base, float64x2_t exponent) {
    return _v_exp_f64(vmulq_f64(exponent, _v_log_f64(base)));
}

static inline double _s_pow_f64(double base, double exponent) {
    return _s_exp_f64(exponent * _s_log_f64(base));
}

static inline float64x2_t _v_sqrt_f64(float64x2_t x) {
    return vsqrtq_f64(x);
}

static inline double _s_sqrt_f64(double x) {
    return __builtin_sqrt(x);
}

static inline float64x2_t hwy_iota_f64(void) {
    float64x2_t v = {0.0, 1.0};
    return v;
}

static inline long hwy_all_true_u64(uint64x2_t mask) {
    return (vgetq_lane_u64(mask, 0) != 0) && (vgetq_lane_u64(mask, 1) != 0);
}

static inline long hwy_all_false_u64(uint64x2_t mask) {
    return (vgetq_lane_u64(mask, 0) == 0) && (vgetq_lane_u64(mask, 1) == 0);
}

static inline long hwy_find_first_true_u64(uint64x2_t mask) {
    if (vgetq_lane_u64(mask, 0)) return 0;
    if (vgetq_lane_u64(mask, 1)) return 1;
    return -1;
}

static inline long hwy_count_true_u64(uint64x2_t mask) {
    long count = 0;
    if (vgetq_lane_u64(mask, 0)) count++;
    if (vgetq_lane_u64(mask, 1)) count++;
    return count;
}

static inline uint64x2_t hwy_first_n_u64(long n) {
    uint64x2_t iota = {0, 1};
    return vcltq_u64(iota, vdupq_n_u64((unsigned long)n));
}

static inline long hwy_compress_store_f64(float64x2_t v, uint64x2_t mask, double *dst) {
    long count = 0;
    if (vgetq_lane_u64(mask, 0)) { dst[count++] = vgetq_lane_f64(v, 0); }
    if (vgetq_lane_u64(mask, 1)) { dst[count++] = vgetq_lane_f64(v, 1); }
    return count;
}

#endif

#ifndef GOAT_PARSER
static long scalarArgmin(double *v, long len_v) {
    long bestIdx = 0;
    double minVal = 0;
    long foundValid = 0;
    #pragma clang loop vectorize(disable) interleave(disable)
    for (long i = 0; i < len_v; i++) {
        if (v[i] != v[i]) {
            continue;
        }
        if (!foundValid || v[i] < minVal || (v[i] == minVal && i < bestIdx)) {
            minVal = v[i];
            bestIdx = i;
            foundValid = 1;
        }
    }
    return bestIdx;
}
#endif

void argmin_c_f64_neon(double *v, long *plen_v, long *pout_result) {
    long len_v = *plen_v;
    long lanes = 2;
    if (len_v < lanes) {
        *pout_result = scalarArgmin(v, len_v);
        return;
    }
    float64x2_t minVals = vld1q_f64(v);
    float64x2_t minIdxs = hwy_iota_f64();
    long i = lanes;
    #pragma clang loop vectorize(disable) interleave(disable)
    for (; i + lanes <= len_v; i += lanes) {
        float64x2_t vals = vld1q_f64(v + i);
        float64x2_t curIdxs = vaddq_f64(vdupq_n_f64((double)(i)), hwy_iota_f64());
        uint64x2_t mask = vcltq_f64(vals, minVals);
        minVals = vbslq_f64(mask, vals, minVals);
        minIdxs = vbslq_f64(mask, curIdxs, minIdxs);
    }
    double valsData[2];
    vst1q_f64(valsData, minVals);
    double idxsData[2];
    vst1q_f64(idxsData, minIdxs);
    long bestIdx = 0;
    double minVal = 0;
    long foundValid = 0;
    #pragma clang loop vectorize(disable) interleave(disable)
    for (long j = 0; j < lanes; j++) {
        double val = valsData[j];
        if (val != val) {
            continue;
        }
        long idx = (long)(idxsData[j]);
        if (!foundValid || val < minVal || (val == minVal && idx < bestIdx)) {
            minVal = val;
            bestIdx = idx;
            foundValid = 1;
        }
    }
    #pragma clang loop vectorize(disable) interleave(disable)
    for (; i < len_v; i++) {
        if (v[i] != v[i]) {
            continue;
        }
        if (!foundValid || v[i] < minVal || (v[i] == minVal && i < bestIdx)) {
            minVal = v[i];
            bestIdx = i;
            foundValid = 1;
        }
    }
    *pout_result = bestIdx;
    return;
}
