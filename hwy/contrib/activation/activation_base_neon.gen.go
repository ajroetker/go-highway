// Code generated by github.com/ajroetker/go-highway/cmd/hwygen. DO NOT EDIT.

//go:build arm64

package activation

import (
	stdmath "math"
	"unsafe"

	"github.com/ajroetker/go-highway/hwy"
	"github.com/ajroetker/go-highway/hwy/asm"
	"github.com/ajroetker/go-highway/hwy/contrib/math"
)

// Hoisted constants - pre-broadcasted at package init time
var (
	BaseELU_NEON_vOne_f32          = asm.BroadcastFloat32x4(float32(actOne_f32))
	BaseELU_NEON_vOne_f64          = asm.BroadcastFloat64x2(float64(actOne_f64))
	BaseELU_NEON_vZero_f32         = asm.BroadcastFloat32x4(float32(actZero_f32))
	BaseELU_NEON_vZero_f64         = asm.BroadcastFloat64x2(float64(actZero_f64))
	BaseGELUApprox_NEON_vCoeff_f32 = asm.BroadcastFloat32x4(float32(actGeluApproxCoeff_f32))
	BaseGELUApprox_NEON_vCoeff_f64 = asm.BroadcastFloat64x2(float64(actGeluApproxCoeff_f64))
	BaseGELU_NEON_vHalf_f32        = asm.BroadcastFloat32x4(float32(actHalf_f32))
	BaseGELU_NEON_vHalf_f64        = asm.BroadcastFloat64x2(float64(actHalf_f64))
	BaseGELU_NEON_vInvSqrt2_f32    = asm.BroadcastFloat32x4(float32(actInvSqrt2_f32))
	BaseGELU_NEON_vInvSqrt2_f64    = asm.BroadcastFloat64x2(float64(actInvSqrt2_f64))
	BaseGELU_NEON_vOne_f32         = asm.BroadcastFloat32x4(float32(actOne_f32))
	BaseGELU_NEON_vOne_f64         = asm.BroadcastFloat64x2(float64(actOne_f64))
	BaseHardSwish_NEON_vBias_f32   = asm.BroadcastFloat32x4(float32(actHalf_f32))
	BaseHardSwish_NEON_vBias_f64   = asm.BroadcastFloat64x2(float64(actHalf_f64))
	BaseHardSwish_NEON_vOne_f32    = asm.BroadcastFloat32x4(float32(actOne_f32))
	BaseHardSwish_NEON_vOne_f64    = asm.BroadcastFloat64x2(float64(actOne_f64))
	BaseHardSwish_NEON_vScale_f32  = asm.BroadcastFloat32x4(float32(actHardSwishScale_f32))
	BaseHardSwish_NEON_vScale_f64  = asm.BroadcastFloat64x2(float64(actHardSwishScale_f64))
	BaseHardSwish_NEON_vZero_f32   = asm.BroadcastFloat32x4(float32(actZero_f32))
	BaseHardSwish_NEON_vZero_f64   = asm.BroadcastFloat64x2(float64(actZero_f64))
	BaseReLU_NEON_vZero_f32        = asm.BroadcastFloat32x4(float32(actZero_f32))
	BaseReLU_NEON_vZero_f64        = asm.BroadcastFloat64x2(float64(actZero_f64))
)

func BaseGELU_neon_Float16(input []hwy.Float16, output []hwy.Float16) {
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	vHalf := hwy.Set[hwy.Float16](actHalf_f16)
	vOne := hwy.Set[hwy.Float16](actOne_f16)
	vInvSqrt2 := hwy.Set[hwy.Float16](actInvSqrt2_f16)
	lanes := 8
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := hwy.Load(input[ii:])
		xScaled := hwy.MulF16(x, vInvSqrt2)
		erfX := math.BaseErfVec_neon_Float16(xScaled)
		onePlusErf := hwy.AddF16(vOne, erfX)
		halfOnePlusErf := hwy.MulF16(vHalf, onePlusErf)
		result := hwy.MulF16(x, halfOnePlusErf)
		hwy.Store(result, output[ii:])
		x1 := hwy.Load(input[ii+8:])
		xScaled1 := hwy.MulF16(x1, vInvSqrt2)
		erfX1 := math.BaseErfVec_neon_Float16(xScaled1)
		onePlusErf1 := hwy.AddF16(vOne, erfX1)
		halfOnePlusErf1 := hwy.MulF16(vHalf, onePlusErf1)
		result1 := hwy.MulF16(x1, halfOnePlusErf1)
		hwy.Store(result1, output[ii+8:])
	}
	for ; ii+lanes <= size; ii += lanes {
		x := hwy.Load(input[ii:])
		xScaled := hwy.MulF16(x, vInvSqrt2)
		erfX := math.BaseErfVec_neon_Float16(xScaled)
		onePlusErf := hwy.AddF16(vOne, erfX)
		halfOnePlusErf := hwy.MulF16(vHalf, onePlusErf)
		result := hwy.MulF16(x, halfOnePlusErf)
		hwy.Store(result, output[ii:])
	}
	for i := ii; i < size; i++ {
		x := float64(input[i].Float32())
		output[i] = hwy.Float32ToFloat16(float32(x * 0.5 * (1.0 + stdmath.Erf(x*0.7071067811865476))))
	}
}

func BaseGELU_neon_BFloat16(input []hwy.BFloat16, output []hwy.BFloat16) {
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	vHalf := hwy.Set[hwy.BFloat16](actHalf_bf16)
	vOne := hwy.Set[hwy.BFloat16](actOne_bf16)
	vInvSqrt2 := hwy.Set[hwy.BFloat16](actInvSqrt2_bf16)
	lanes := 8
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := hwy.Load(input[ii:])
		xScaled := hwy.MulBF16(x, vInvSqrt2)
		erfX := math.BaseErfVec_neon_BFloat16(xScaled)
		onePlusErf := hwy.AddBF16(vOne, erfX)
		halfOnePlusErf := hwy.MulBF16(vHalf, onePlusErf)
		result := hwy.MulBF16(x, halfOnePlusErf)
		hwy.Store(result, output[ii:])
		x1 := hwy.Load(input[ii+8:])
		xScaled1 := hwy.MulBF16(x1, vInvSqrt2)
		erfX1 := math.BaseErfVec_neon_BFloat16(xScaled1)
		onePlusErf1 := hwy.AddBF16(vOne, erfX1)
		halfOnePlusErf1 := hwy.MulBF16(vHalf, onePlusErf1)
		result1 := hwy.MulBF16(x1, halfOnePlusErf1)
		hwy.Store(result1, output[ii+8:])
	}
	for ; ii+lanes <= size; ii += lanes {
		x := hwy.Load(input[ii:])
		xScaled := hwy.MulBF16(x, vInvSqrt2)
		erfX := math.BaseErfVec_neon_BFloat16(xScaled)
		onePlusErf := hwy.AddBF16(vOne, erfX)
		halfOnePlusErf := hwy.MulBF16(vHalf, onePlusErf)
		result := hwy.MulBF16(x, halfOnePlusErf)
		hwy.Store(result, output[ii:])
	}
	for i := ii; i < size; i++ {
		x := float64(input[i].Float32())
		output[i] = hwy.Float32ToBFloat16(float32(x * 0.5 * (1.0 + stdmath.Erf(x*0.7071067811865476))))
	}
}

func BaseGELU_neon(input []float32, output []float32) {
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	vHalf := BaseGELU_NEON_vHalf_f32
	vOne := BaseGELU_NEON_vOne_f32
	vInvSqrt2 := BaseGELU_NEON_vInvSqrt2_f32
	lanes := 4
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := asm.LoadFloat32x4((*[4]float32)(unsafe.Pointer(&input[ii])))
		xScaled := x.Mul(vInvSqrt2)
		erfX := math.BaseErfVec_neon(xScaled)
		onePlusErf := vOne.Add(erfX)
		halfOnePlusErf := vHalf.Mul(onePlusErf)
		result := x.Mul(halfOnePlusErf)
		result.Store((*[4]float32)(unsafe.Pointer(&output[ii])))
		x1 := asm.LoadFloat32x4((*[4]float32)(unsafe.Pointer(&input[ii+4])))
		xScaled1 := x1.Mul(vInvSqrt2)
		erfX1 := math.BaseErfVec_neon(xScaled1)
		onePlusErf1 := vOne.Add(erfX1)
		halfOnePlusErf1 := vHalf.Mul(onePlusErf1)
		result1 := x1.Mul(halfOnePlusErf1)
		result1.Store((*[4]float32)(unsafe.Pointer(&output[ii+4])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := asm.LoadFloat32x4((*[4]float32)(unsafe.Pointer(&input[ii])))
		xScaled := x.Mul(vInvSqrt2)
		erfX := math.BaseErfVec_neon(xScaled)
		onePlusErf := vOne.Add(erfX)
		halfOnePlusErf := vHalf.Mul(onePlusErf)
		result := x.Mul(halfOnePlusErf)
		result.Store((*[4]float32)(unsafe.Pointer(&output[ii])))
	}
	for i := ii; i < size; i++ {
		x := float64(input[i])
		output[i] = float32(x * 0.5 * (1.0 + stdmath.Erf(x*0.7071067811865476)))
	}
}

func BaseGELU_neon_Float64(input []float64, output []float64) {
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	vHalf := BaseGELU_NEON_vHalf_f64
	vOne := BaseGELU_NEON_vOne_f64
	vInvSqrt2 := BaseGELU_NEON_vInvSqrt2_f64
	lanes := 2
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := asm.LoadFloat64x2((*[2]float64)(unsafe.Pointer(&input[ii])))
		xScaled := x.Mul(vInvSqrt2)
		erfX := math.BaseErfVec_neon_Float64(xScaled)
		onePlusErf := vOne.Add(erfX)
		halfOnePlusErf := vHalf.Mul(onePlusErf)
		result := x.Mul(halfOnePlusErf)
		result.Store((*[2]float64)(unsafe.Pointer(&output[ii])))
		x1 := asm.LoadFloat64x2((*[2]float64)(unsafe.Pointer(&input[ii+2])))
		xScaled1 := x1.Mul(vInvSqrt2)
		erfX1 := math.BaseErfVec_neon_Float64(xScaled1)
		onePlusErf1 := vOne.Add(erfX1)
		halfOnePlusErf1 := vHalf.Mul(onePlusErf1)
		result1 := x1.Mul(halfOnePlusErf1)
		result1.Store((*[2]float64)(unsafe.Pointer(&output[ii+2])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := asm.LoadFloat64x2((*[2]float64)(unsafe.Pointer(&input[ii])))
		xScaled := x.Mul(vInvSqrt2)
		erfX := math.BaseErfVec_neon_Float64(xScaled)
		onePlusErf := vOne.Add(erfX)
		halfOnePlusErf := vHalf.Mul(onePlusErf)
		result := x.Mul(halfOnePlusErf)
		result.Store((*[2]float64)(unsafe.Pointer(&output[ii])))
	}
	for i := ii; i < size; i++ {
		x := float64(input[i])
		output[i] = float64(x * 0.5 * (1.0 + stdmath.Erf(x*0.7071067811865476)))
	}
}

func BaseGELUApprox_neon_Float16(input []hwy.Float16, output []hwy.Float16) {
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	vCoeff := hwy.Set[hwy.Float16](actGeluApproxCoeff_f16)
	lanes := 8
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := hwy.Load(input[ii:])
		xScaled := hwy.MulF16(x, vCoeff)
		sigmoidX := math.BaseSigmoidVec_neon_Float16(xScaled)
		result := hwy.MulF16(x, sigmoidX)
		hwy.Store(result, output[ii:])
		x1 := hwy.Load(input[ii+8:])
		xScaled1 := hwy.MulF16(x1, vCoeff)
		sigmoidX1 := math.BaseSigmoidVec_neon_Float16(xScaled1)
		result1 := hwy.MulF16(x1, sigmoidX1)
		hwy.Store(result1, output[ii+8:])
	}
	for ; ii+lanes <= size; ii += lanes {
		x := hwy.Load(input[ii:])
		xScaled := hwy.MulF16(x, vCoeff)
		sigmoidX := math.BaseSigmoidVec_neon_Float16(xScaled)
		result := hwy.MulF16(x, sigmoidX)
		hwy.Store(result, output[ii:])
	}
	for i := ii; i < size; i++ {
		x := float64(input[i].Float32())
		sigmoid := 1.0 / (1.0 + stdmath.Exp(-1.702*x))
		output[i] = hwy.Float32ToFloat16(float32(x * sigmoid))
	}
}

func BaseGELUApprox_neon_BFloat16(input []hwy.BFloat16, output []hwy.BFloat16) {
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	vCoeff := hwy.Set[hwy.BFloat16](actGeluApproxCoeff_bf16)
	lanes := 8
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := hwy.Load(input[ii:])
		xScaled := hwy.MulBF16(x, vCoeff)
		sigmoidX := math.BaseSigmoidVec_neon_BFloat16(xScaled)
		result := hwy.MulBF16(x, sigmoidX)
		hwy.Store(result, output[ii:])
		x1 := hwy.Load(input[ii+8:])
		xScaled1 := hwy.MulBF16(x1, vCoeff)
		sigmoidX1 := math.BaseSigmoidVec_neon_BFloat16(xScaled1)
		result1 := hwy.MulBF16(x1, sigmoidX1)
		hwy.Store(result1, output[ii+8:])
	}
	for ; ii+lanes <= size; ii += lanes {
		x := hwy.Load(input[ii:])
		xScaled := hwy.MulBF16(x, vCoeff)
		sigmoidX := math.BaseSigmoidVec_neon_BFloat16(xScaled)
		result := hwy.MulBF16(x, sigmoidX)
		hwy.Store(result, output[ii:])
	}
	for i := ii; i < size; i++ {
		x := float64(input[i].Float32())
		sigmoid := 1.0 / (1.0 + stdmath.Exp(-1.702*x))
		output[i] = hwy.Float32ToBFloat16(float32(x * sigmoid))
	}
}

func BaseGELUApprox_neon(input []float32, output []float32) {
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	vCoeff := BaseGELUApprox_NEON_vCoeff_f32
	lanes := 4
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := asm.LoadFloat32x4((*[4]float32)(unsafe.Pointer(&input[ii])))
		xScaled := x.Mul(vCoeff)
		sigmoidX := math.BaseSigmoidVec_neon(xScaled)
		result := x.Mul(sigmoidX)
		result.Store((*[4]float32)(unsafe.Pointer(&output[ii])))
		x1 := asm.LoadFloat32x4((*[4]float32)(unsafe.Pointer(&input[ii+4])))
		xScaled1 := x1.Mul(vCoeff)
		sigmoidX1 := math.BaseSigmoidVec_neon(xScaled1)
		result1 := x1.Mul(sigmoidX1)
		result1.Store((*[4]float32)(unsafe.Pointer(&output[ii+4])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := asm.LoadFloat32x4((*[4]float32)(unsafe.Pointer(&input[ii])))
		xScaled := x.Mul(vCoeff)
		sigmoidX := math.BaseSigmoidVec_neon(xScaled)
		result := x.Mul(sigmoidX)
		result.Store((*[4]float32)(unsafe.Pointer(&output[ii])))
	}
	for i := ii; i < size; i++ {
		x := float64(input[i])
		sigmoid := 1.0 / (1.0 + stdmath.Exp(-1.702*x))
		output[i] = float32(x * sigmoid)
	}
}

func BaseGELUApprox_neon_Float64(input []float64, output []float64) {
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	vCoeff := BaseGELUApprox_NEON_vCoeff_f64
	lanes := 2
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := asm.LoadFloat64x2((*[2]float64)(unsafe.Pointer(&input[ii])))
		xScaled := x.Mul(vCoeff)
		sigmoidX := math.BaseSigmoidVec_neon_Float64(xScaled)
		result := x.Mul(sigmoidX)
		result.Store((*[2]float64)(unsafe.Pointer(&output[ii])))
		x1 := asm.LoadFloat64x2((*[2]float64)(unsafe.Pointer(&input[ii+2])))
		xScaled1 := x1.Mul(vCoeff)
		sigmoidX1 := math.BaseSigmoidVec_neon_Float64(xScaled1)
		result1 := x1.Mul(sigmoidX1)
		result1.Store((*[2]float64)(unsafe.Pointer(&output[ii+2])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := asm.LoadFloat64x2((*[2]float64)(unsafe.Pointer(&input[ii])))
		xScaled := x.Mul(vCoeff)
		sigmoidX := math.BaseSigmoidVec_neon_Float64(xScaled)
		result := x.Mul(sigmoidX)
		result.Store((*[2]float64)(unsafe.Pointer(&output[ii])))
	}
	for i := ii; i < size; i++ {
		x := float64(input[i])
		sigmoid := 1.0 / (1.0 + stdmath.Exp(-1.702*x))
		output[i] = float64(x * sigmoid)
	}
}

func BaseReLU_neon_Float16(input []hwy.Float16, output []hwy.Float16) {
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	vZero := asm.BroadcastFloat16x8(uint16(actZero_f16))
	lanes := 8
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := asm.LoadFloat16x8Ptr(unsafe.Pointer(&input[ii:][0]))
		result := x.Max(vZero)
		result.StorePtr(unsafe.Pointer(&output[ii:][0]))
		x1 := asm.LoadFloat16x8Ptr(unsafe.Pointer(&input[ii+8:][0]))
		result1 := x1.Max(vZero)
		result1.StorePtr(unsafe.Pointer(&output[ii+8:][0]))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := asm.LoadFloat16x8Ptr(unsafe.Pointer(&input[ii:][0]))
		result := x.Max(vZero)
		result.StorePtr(unsafe.Pointer(&output[ii:][0]))
	}
	for i := ii; i < size; i++ {
		if input[i].Float32() > 0 {
			output[i] = hwy.Float32ToFloat16(input[i].Float32())
		} else {
			output[i] = hwy.Float32ToFloat16(0)
		}
	}
}

func BaseReLU_neon_BFloat16(input []hwy.BFloat16, output []hwy.BFloat16) {
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	vZero := asm.BroadcastBFloat16x8(uint16(actZero_bf16))
	lanes := 8
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := asm.LoadBFloat16x8Ptr(unsafe.Pointer(&input[ii:][0]))
		result := x.Max(vZero)
		result.StorePtr(unsafe.Pointer(&output[ii:][0]))
		x1 := asm.LoadBFloat16x8Ptr(unsafe.Pointer(&input[ii+8:][0]))
		result1 := x1.Max(vZero)
		result1.StorePtr(unsafe.Pointer(&output[ii+8:][0]))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := asm.LoadBFloat16x8Ptr(unsafe.Pointer(&input[ii:][0]))
		result := x.Max(vZero)
		result.StorePtr(unsafe.Pointer(&output[ii:][0]))
	}
	for i := ii; i < size; i++ {
		if input[i].Float32() > 0 {
			output[i] = hwy.Float32ToBFloat16(input[i].Float32())
		} else {
			output[i] = hwy.Float32ToBFloat16(0)
		}
	}
}

func BaseReLU_neon(input []float32, output []float32) {
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	vZero := BaseReLU_NEON_vZero_f32
	lanes := 4
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := asm.LoadFloat32x4((*[4]float32)(unsafe.Pointer(&input[ii])))
		result := x.Max(vZero)
		result.Store((*[4]float32)(unsafe.Pointer(&output[ii])))
		x1 := asm.LoadFloat32x4((*[4]float32)(unsafe.Pointer(&input[ii+4])))
		result1 := x1.Max(vZero)
		result1.Store((*[4]float32)(unsafe.Pointer(&output[ii+4])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := asm.LoadFloat32x4((*[4]float32)(unsafe.Pointer(&input[ii])))
		result := x.Max(vZero)
		result.Store((*[4]float32)(unsafe.Pointer(&output[ii])))
	}
	for i := ii; i < size; i++ {
		if input[i] > 0 {
			output[i] = input[i]
		} else {
			output[i] = 0
		}
	}
}

func BaseReLU_neon_Float64(input []float64, output []float64) {
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	vZero := BaseReLU_NEON_vZero_f64
	lanes := 2
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := asm.LoadFloat64x2((*[2]float64)(unsafe.Pointer(&input[ii])))
		result := x.Max(vZero)
		result.Store((*[2]float64)(unsafe.Pointer(&output[ii])))
		x1 := asm.LoadFloat64x2((*[2]float64)(unsafe.Pointer(&input[ii+2])))
		result1 := x1.Max(vZero)
		result1.Store((*[2]float64)(unsafe.Pointer(&output[ii+2])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := asm.LoadFloat64x2((*[2]float64)(unsafe.Pointer(&input[ii])))
		result := x.Max(vZero)
		result.Store((*[2]float64)(unsafe.Pointer(&output[ii])))
	}
	for i := ii; i < size; i++ {
		if input[i] > 0 {
			output[i] = input[i]
		} else {
			output[i] = 0
		}
	}
}

func BaseSiLU_neon_Float16(input []hwy.Float16, output []hwy.Float16) {
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	lanes := 8
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := hwy.Load(input[ii:])
		sigmoidX := math.BaseSigmoidVec_neon_Float16(x)
		result := hwy.MulF16(x, sigmoidX)
		hwy.Store(result, output[ii:])
		x1 := hwy.Load(input[ii+8:])
		sigmoidX1 := math.BaseSigmoidVec_neon_Float16(x1)
		result1 := hwy.MulF16(x1, sigmoidX1)
		hwy.Store(result1, output[ii+8:])
	}
	for ; ii+lanes <= size; ii += lanes {
		x := hwy.Load(input[ii:])
		sigmoidX := math.BaseSigmoidVec_neon_Float16(x)
		result := hwy.MulF16(x, sigmoidX)
		hwy.Store(result, output[ii:])
	}
	for i := ii; i < size; i++ {
		x := float64(input[i].Float32())
		sigmoid := 1.0 / (1.0 + stdmath.Exp(-x))
		output[i] = hwy.Float32ToFloat16(float32(x * sigmoid))
	}
}

func BaseSiLU_neon_BFloat16(input []hwy.BFloat16, output []hwy.BFloat16) {
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	lanes := 8
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := hwy.Load(input[ii:])
		sigmoidX := math.BaseSigmoidVec_neon_BFloat16(x)
		result := hwy.MulBF16(x, sigmoidX)
		hwy.Store(result, output[ii:])
		x1 := hwy.Load(input[ii+8:])
		sigmoidX1 := math.BaseSigmoidVec_neon_BFloat16(x1)
		result1 := hwy.MulBF16(x1, sigmoidX1)
		hwy.Store(result1, output[ii+8:])
	}
	for ; ii+lanes <= size; ii += lanes {
		x := hwy.Load(input[ii:])
		sigmoidX := math.BaseSigmoidVec_neon_BFloat16(x)
		result := hwy.MulBF16(x, sigmoidX)
		hwy.Store(result, output[ii:])
	}
	for i := ii; i < size; i++ {
		x := float64(input[i].Float32())
		sigmoid := 1.0 / (1.0 + stdmath.Exp(-x))
		output[i] = hwy.Float32ToBFloat16(float32(x * sigmoid))
	}
}

func BaseSiLU_neon(input []float32, output []float32) {
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	lanes := 4
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := asm.LoadFloat32x4((*[4]float32)(unsafe.Pointer(&input[ii])))
		sigmoidX := math.BaseSigmoidVec_neon(x)
		result := x.Mul(sigmoidX)
		result.Store((*[4]float32)(unsafe.Pointer(&output[ii])))
		x1 := asm.LoadFloat32x4((*[4]float32)(unsafe.Pointer(&input[ii+4])))
		sigmoidX1 := math.BaseSigmoidVec_neon(x1)
		result1 := x1.Mul(sigmoidX1)
		result1.Store((*[4]float32)(unsafe.Pointer(&output[ii+4])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := asm.LoadFloat32x4((*[4]float32)(unsafe.Pointer(&input[ii])))
		sigmoidX := math.BaseSigmoidVec_neon(x)
		result := x.Mul(sigmoidX)
		result.Store((*[4]float32)(unsafe.Pointer(&output[ii])))
	}
	for i := ii; i < size; i++ {
		x := float64(input[i])
		sigmoid := 1.0 / (1.0 + stdmath.Exp(-x))
		output[i] = float32(x * sigmoid)
	}
}

func BaseSiLU_neon_Float64(input []float64, output []float64) {
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	lanes := 2
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := asm.LoadFloat64x2((*[2]float64)(unsafe.Pointer(&input[ii])))
		sigmoidX := math.BaseSigmoidVec_neon_Float64(x)
		result := x.Mul(sigmoidX)
		result.Store((*[2]float64)(unsafe.Pointer(&output[ii])))
		x1 := asm.LoadFloat64x2((*[2]float64)(unsafe.Pointer(&input[ii+2])))
		sigmoidX1 := math.BaseSigmoidVec_neon_Float64(x1)
		result1 := x1.Mul(sigmoidX1)
		result1.Store((*[2]float64)(unsafe.Pointer(&output[ii+2])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := asm.LoadFloat64x2((*[2]float64)(unsafe.Pointer(&input[ii])))
		sigmoidX := math.BaseSigmoidVec_neon_Float64(x)
		result := x.Mul(sigmoidX)
		result.Store((*[2]float64)(unsafe.Pointer(&output[ii])))
	}
	for i := ii; i < size; i++ {
		x := float64(input[i])
		sigmoid := 1.0 / (1.0 + stdmath.Exp(-x))
		output[i] = float64(x * sigmoid)
	}
}

func BaseLeakyReLU_neon_Float16(input []hwy.Float16, output []hwy.Float16, alpha hwy.Float16) {
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	vAlpha := asm.BroadcastFloat16x8(uint16(alpha))
	lanes := 8
	ii := 0
	for ; ii+lanes*4 <= size; ii += lanes * 4 {
		x := asm.LoadFloat16x8Ptr(unsafe.Pointer(&input[ii:][0]))
		negPart := x.Mul(vAlpha)
		result := x.Max(negPart)
		result.StorePtr(unsafe.Pointer(&output[ii:][0]))
		x1 := asm.LoadFloat16x8Ptr(unsafe.Pointer(&input[ii+8:][0]))
		negPart1 := x1.Mul(vAlpha)
		result1 := x1.Max(negPart1)
		result1.StorePtr(unsafe.Pointer(&output[ii+8:][0]))
		x2 := asm.LoadFloat16x8Ptr(unsafe.Pointer(&input[ii+16:][0]))
		negPart2 := x2.Mul(vAlpha)
		result2 := x2.Max(negPart2)
		result2.StorePtr(unsafe.Pointer(&output[ii+16:][0]))
		x3 := asm.LoadFloat16x8Ptr(unsafe.Pointer(&input[ii+24:][0]))
		negPart3 := x3.Mul(vAlpha)
		result3 := x3.Max(negPart3)
		result3.StorePtr(unsafe.Pointer(&output[ii+24:][0]))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := asm.LoadFloat16x8Ptr(unsafe.Pointer(&input[ii:][0]))
		negPart := x.Mul(vAlpha)
		result := x.Max(negPart)
		result.StorePtr(unsafe.Pointer(&output[ii:][0]))
	}
	for i := ii; i < size; i++ {
		if input[i].Float32() > 0 {
			output[i] = hwy.Float32ToFloat16(input[i].Float32())
		} else {
			output[i] = hwy.Float32ToFloat16(alpha.Float32() * input[i].Float32())
		}
	}
}

func BaseLeakyReLU_neon_BFloat16(input []hwy.BFloat16, output []hwy.BFloat16, alpha hwy.BFloat16) {
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	vAlpha := asm.BroadcastBFloat16x8(uint16(alpha))
	lanes := 8
	ii := 0
	for ; ii+lanes*4 <= size; ii += lanes * 4 {
		x := asm.LoadBFloat16x8Ptr(unsafe.Pointer(&input[ii:][0]))
		negPart := x.Mul(vAlpha)
		result := x.Max(negPart)
		result.StorePtr(unsafe.Pointer(&output[ii:][0]))
		x1 := asm.LoadBFloat16x8Ptr(unsafe.Pointer(&input[ii+8:][0]))
		negPart1 := x1.Mul(vAlpha)
		result1 := x1.Max(negPart1)
		result1.StorePtr(unsafe.Pointer(&output[ii+8:][0]))
		x2 := asm.LoadBFloat16x8Ptr(unsafe.Pointer(&input[ii+16:][0]))
		negPart2 := x2.Mul(vAlpha)
		result2 := x2.Max(negPart2)
		result2.StorePtr(unsafe.Pointer(&output[ii+16:][0]))
		x3 := asm.LoadBFloat16x8Ptr(unsafe.Pointer(&input[ii+24:][0]))
		negPart3 := x3.Mul(vAlpha)
		result3 := x3.Max(negPart3)
		result3.StorePtr(unsafe.Pointer(&output[ii+24:][0]))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := asm.LoadBFloat16x8Ptr(unsafe.Pointer(&input[ii:][0]))
		negPart := x.Mul(vAlpha)
		result := x.Max(negPart)
		result.StorePtr(unsafe.Pointer(&output[ii:][0]))
	}
	for i := ii; i < size; i++ {
		if input[i].Float32() > 0 {
			output[i] = hwy.Float32ToBFloat16(input[i].Float32())
		} else {
			output[i] = hwy.Float32ToBFloat16(alpha.Float32() * input[i].Float32())
		}
	}
}

func BaseLeakyReLU_neon(input []float32, output []float32, alpha float32) {
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	vAlpha := asm.BroadcastFloat32x4(alpha)
	lanes := 4
	ii := 0
	for ; ii+lanes*4 <= size; ii += lanes * 4 {
		x := asm.LoadFloat32x4((*[4]float32)(unsafe.Pointer(&input[ii])))
		negPart := x.Mul(vAlpha)
		result := x.Max(negPart)
		result.Store((*[4]float32)(unsafe.Pointer(&output[ii])))
		x1 := asm.LoadFloat32x4((*[4]float32)(unsafe.Pointer(&input[ii+4])))
		negPart1 := x1.Mul(vAlpha)
		result1 := x1.Max(negPart1)
		result1.Store((*[4]float32)(unsafe.Pointer(&output[ii+4])))
		x2 := asm.LoadFloat32x4((*[4]float32)(unsafe.Pointer(&input[ii+8])))
		negPart2 := x2.Mul(vAlpha)
		result2 := x2.Max(negPart2)
		result2.Store((*[4]float32)(unsafe.Pointer(&output[ii+8])))
		x3 := asm.LoadFloat32x4((*[4]float32)(unsafe.Pointer(&input[ii+12])))
		negPart3 := x3.Mul(vAlpha)
		result3 := x3.Max(negPart3)
		result3.Store((*[4]float32)(unsafe.Pointer(&output[ii+12])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := asm.LoadFloat32x4((*[4]float32)(unsafe.Pointer(&input[ii])))
		negPart := x.Mul(vAlpha)
		result := x.Max(negPart)
		result.Store((*[4]float32)(unsafe.Pointer(&output[ii])))
	}
	for i := ii; i < size; i++ {
		if input[i] > 0 {
			output[i] = input[i]
		} else {
			output[i] = alpha * input[i]
		}
	}
}

func BaseLeakyReLU_neon_Float64(input []float64, output []float64, alpha float64) {
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	vAlpha := asm.BroadcastFloat64x2(alpha)
	lanes := 2
	ii := 0
	for ; ii+lanes*4 <= size; ii += lanes * 4 {
		x := asm.LoadFloat64x2((*[2]float64)(unsafe.Pointer(&input[ii])))
		negPart := x.Mul(vAlpha)
		result := x.Max(negPart)
		result.Store((*[2]float64)(unsafe.Pointer(&output[ii])))
		x1 := asm.LoadFloat64x2((*[2]float64)(unsafe.Pointer(&input[ii+2])))
		negPart1 := x1.Mul(vAlpha)
		result1 := x1.Max(negPart1)
		result1.Store((*[2]float64)(unsafe.Pointer(&output[ii+2])))
		x2 := asm.LoadFloat64x2((*[2]float64)(unsafe.Pointer(&input[ii+4])))
		negPart2 := x2.Mul(vAlpha)
		result2 := x2.Max(negPart2)
		result2.Store((*[2]float64)(unsafe.Pointer(&output[ii+4])))
		x3 := asm.LoadFloat64x2((*[2]float64)(unsafe.Pointer(&input[ii+6])))
		negPart3 := x3.Mul(vAlpha)
		result3 := x3.Max(negPart3)
		result3.Store((*[2]float64)(unsafe.Pointer(&output[ii+6])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := asm.LoadFloat64x2((*[2]float64)(unsafe.Pointer(&input[ii])))
		negPart := x.Mul(vAlpha)
		result := x.Max(negPart)
		result.Store((*[2]float64)(unsafe.Pointer(&output[ii])))
	}
	for i := ii; i < size; i++ {
		if input[i] > 0 {
			output[i] = input[i]
		} else {
			output[i] = alpha * input[i]
		}
	}
}

func BaseTanh_neon_Float16(input []hwy.Float16, output []hwy.Float16) {
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	lanes := 8
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := hwy.Load(input[ii:])
		result := math.BaseTanhVec_neon_Float16(x)
		hwy.Store(result, output[ii:])
		x1 := hwy.Load(input[ii+8:])
		result1 := math.BaseTanhVec_neon_Float16(x1)
		hwy.Store(result1, output[ii+8:])
	}
	for ; ii+lanes <= size; ii += lanes {
		x := hwy.Load(input[ii:])
		result := math.BaseTanhVec_neon_Float16(x)
		hwy.Store(result, output[ii:])
	}
	for i := ii; i < size; i++ {
		x := float64(input[i].Float32())
		output[i] = hwy.Float32ToFloat16(float32(stdmath.Tanh(x)))
	}
}

func BaseTanh_neon_BFloat16(input []hwy.BFloat16, output []hwy.BFloat16) {
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	lanes := 8
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := hwy.Load(input[ii:])
		result := math.BaseTanhVec_neon_BFloat16(x)
		hwy.Store(result, output[ii:])
		x1 := hwy.Load(input[ii+8:])
		result1 := math.BaseTanhVec_neon_BFloat16(x1)
		hwy.Store(result1, output[ii+8:])
	}
	for ; ii+lanes <= size; ii += lanes {
		x := hwy.Load(input[ii:])
		result := math.BaseTanhVec_neon_BFloat16(x)
		hwy.Store(result, output[ii:])
	}
	for i := ii; i < size; i++ {
		x := float64(input[i].Float32())
		output[i] = hwy.Float32ToBFloat16(float32(stdmath.Tanh(x)))
	}
}

func BaseTanh_neon(input []float32, output []float32) {
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	lanes := 4
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := asm.LoadFloat32x4((*[4]float32)(unsafe.Pointer(&input[ii])))
		result := math.BaseTanhVec_neon(x)
		result.Store((*[4]float32)(unsafe.Pointer(&output[ii])))
		x1 := asm.LoadFloat32x4((*[4]float32)(unsafe.Pointer(&input[ii+4])))
		result1 := math.BaseTanhVec_neon(x1)
		result1.Store((*[4]float32)(unsafe.Pointer(&output[ii+4])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := asm.LoadFloat32x4((*[4]float32)(unsafe.Pointer(&input[ii])))
		result := math.BaseTanhVec_neon(x)
		result.Store((*[4]float32)(unsafe.Pointer(&output[ii])))
	}
	for i := ii; i < size; i++ {
		x := float64(input[i])
		output[i] = float32(stdmath.Tanh(x))
	}
}

func BaseTanh_neon_Float64(input []float64, output []float64) {
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	lanes := 2
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := asm.LoadFloat64x2((*[2]float64)(unsafe.Pointer(&input[ii])))
		result := math.BaseTanhVec_neon_Float64(x)
		result.Store((*[2]float64)(unsafe.Pointer(&output[ii])))
		x1 := asm.LoadFloat64x2((*[2]float64)(unsafe.Pointer(&input[ii+2])))
		result1 := math.BaseTanhVec_neon_Float64(x1)
		result1.Store((*[2]float64)(unsafe.Pointer(&output[ii+2])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := asm.LoadFloat64x2((*[2]float64)(unsafe.Pointer(&input[ii])))
		result := math.BaseTanhVec_neon_Float64(x)
		result.Store((*[2]float64)(unsafe.Pointer(&output[ii])))
	}
	for i := ii; i < size; i++ {
		x := float64(input[i])
		output[i] = float64(stdmath.Tanh(x))
	}
}

func BaseHardSwish_neon_Float16(input []hwy.Float16, output []hwy.Float16) {
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	vZero := asm.BroadcastFloat16x8(uint16(actZero_f16))
	vOne := asm.BroadcastFloat16x8(uint16(actOne_f16))
	vScale := asm.BroadcastFloat16x8(uint16(actHardSwishScale_f16))
	vBias := asm.BroadcastFloat16x8(uint16(actHalf_f16))
	lanes := 8
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := asm.LoadFloat16x8Ptr(unsafe.Pointer(&input[ii:][0]))
		s := x.Mul(vScale).Add(vBias)
		s = s.Max(vZero)
		s = s.Min(vOne)
		result := x.Mul(s)
		result.StorePtr(unsafe.Pointer(&output[ii:][0]))
		x1 := asm.LoadFloat16x8Ptr(unsafe.Pointer(&input[ii+8:][0]))
		s1 := x1.Mul(vScale).Add(vBias)
		s1 = s1.Max(vZero)
		s1 = s1.Min(vOne)
		result1 := x1.Mul(s1)
		result1.StorePtr(unsafe.Pointer(&output[ii+8:][0]))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := asm.LoadFloat16x8Ptr(unsafe.Pointer(&input[ii:][0]))
		s := x.Mul(vScale).Add(vBias)
		s = s.Max(vZero)
		s = s.Min(vOne)
		result := x.Mul(s)
		result.StorePtr(unsafe.Pointer(&output[ii:][0]))
	}
	for i := ii; i < size; i++ {
		x := float64(input[i].Float32())
		s := x/6.0 + 0.5
		if s < 0 {
			s = 0
		} else if s > 1 {
			s = 1
		}
		output[i] = hwy.Float32ToFloat16(float32(x * s))
	}
}

func BaseHardSwish_neon_BFloat16(input []hwy.BFloat16, output []hwy.BFloat16) {
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	vZero := asm.BroadcastBFloat16x8(uint16(actZero_bf16))
	vOne := asm.BroadcastBFloat16x8(uint16(actOne_bf16))
	vScale := asm.BroadcastBFloat16x8(uint16(actHardSwishScale_bf16))
	vBias := asm.BroadcastBFloat16x8(uint16(actHalf_bf16))
	lanes := 8
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := asm.LoadBFloat16x8Ptr(unsafe.Pointer(&input[ii:][0]))
		s := x.Mul(vScale).Add(vBias)
		s = s.Max(vZero)
		s = s.Min(vOne)
		result := x.Mul(s)
		result.StorePtr(unsafe.Pointer(&output[ii:][0]))
		x1 := asm.LoadBFloat16x8Ptr(unsafe.Pointer(&input[ii+8:][0]))
		s1 := x1.Mul(vScale).Add(vBias)
		s1 = s1.Max(vZero)
		s1 = s1.Min(vOne)
		result1 := x1.Mul(s1)
		result1.StorePtr(unsafe.Pointer(&output[ii+8:][0]))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := asm.LoadBFloat16x8Ptr(unsafe.Pointer(&input[ii:][0]))
		s := x.Mul(vScale).Add(vBias)
		s = s.Max(vZero)
		s = s.Min(vOne)
		result := x.Mul(s)
		result.StorePtr(unsafe.Pointer(&output[ii:][0]))
	}
	for i := ii; i < size; i++ {
		x := float64(input[i].Float32())
		s := x/6.0 + 0.5
		if s < 0 {
			s = 0
		} else if s > 1 {
			s = 1
		}
		output[i] = hwy.Float32ToBFloat16(float32(x * s))
	}
}

func BaseHardSwish_neon(input []float32, output []float32) {
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	vZero := BaseHardSwish_NEON_vZero_f32
	vOne := BaseHardSwish_NEON_vOne_f32
	vScale := BaseHardSwish_NEON_vScale_f32
	vBias := BaseHardSwish_NEON_vBias_f32
	lanes := 4
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := asm.LoadFloat32x4((*[4]float32)(unsafe.Pointer(&input[ii])))
		s := x.Mul(vScale).Add(vBias)
		s = s.Max(vZero)
		s = s.Min(vOne)
		result := x.Mul(s)
		result.Store((*[4]float32)(unsafe.Pointer(&output[ii])))
		x1 := asm.LoadFloat32x4((*[4]float32)(unsafe.Pointer(&input[ii+4])))
		s1 := x1.Mul(vScale).Add(vBias)
		s1 = s1.Max(vZero)
		s1 = s1.Min(vOne)
		result1 := x1.Mul(s1)
		result1.Store((*[4]float32)(unsafe.Pointer(&output[ii+4])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := asm.LoadFloat32x4((*[4]float32)(unsafe.Pointer(&input[ii])))
		s := x.Mul(vScale).Add(vBias)
		s = s.Max(vZero)
		s = s.Min(vOne)
		result := x.Mul(s)
		result.Store((*[4]float32)(unsafe.Pointer(&output[ii])))
	}
	for i := ii; i < size; i++ {
		x := float64(input[i])
		s := x/6.0 + 0.5
		if s < 0 {
			s = 0
		} else if s > 1 {
			s = 1
		}
		output[i] = float32(x * s)
	}
}

func BaseHardSwish_neon_Float64(input []float64, output []float64) {
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	vZero := BaseHardSwish_NEON_vZero_f64
	vOne := BaseHardSwish_NEON_vOne_f64
	vScale := BaseHardSwish_NEON_vScale_f64
	vBias := BaseHardSwish_NEON_vBias_f64
	lanes := 2
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := asm.LoadFloat64x2((*[2]float64)(unsafe.Pointer(&input[ii])))
		s := x.Mul(vScale).Add(vBias)
		s = s.Max(vZero)
		s = s.Min(vOne)
		result := x.Mul(s)
		result.Store((*[2]float64)(unsafe.Pointer(&output[ii])))
		x1 := asm.LoadFloat64x2((*[2]float64)(unsafe.Pointer(&input[ii+2])))
		s1 := x1.Mul(vScale).Add(vBias)
		s1 = s1.Max(vZero)
		s1 = s1.Min(vOne)
		result1 := x1.Mul(s1)
		result1.Store((*[2]float64)(unsafe.Pointer(&output[ii+2])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := asm.LoadFloat64x2((*[2]float64)(unsafe.Pointer(&input[ii])))
		s := x.Mul(vScale).Add(vBias)
		s = s.Max(vZero)
		s = s.Min(vOne)
		result := x.Mul(s)
		result.Store((*[2]float64)(unsafe.Pointer(&output[ii])))
	}
	for i := ii; i < size; i++ {
		x := float64(input[i])
		s := x/6.0 + 0.5
		if s < 0 {
			s = 0
		} else if s > 1 {
			s = 1
		}
		output[i] = float64(x * s)
	}
}

func BaseELU_neon_Float16(input []hwy.Float16, output []hwy.Float16, alpha hwy.Float16) {
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	vZero := hwy.Set[hwy.Float16](actZero_f16)
	vOne := hwy.Set[hwy.Float16](actOne_f16)
	vAlpha := hwy.Set(alpha)
	lanes := 8
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := hwy.Load(input[ii:])
		expX := math.BaseExpVec_neon_Float16(x)
		expM1 := hwy.SubF16(expX, vOne)
		negPart := hwy.MulF16(vAlpha, expM1)
		isPositive := hwy.GreaterThanF16(x, vZero)
		result := hwy.IfThenElseF16(isPositive, x, negPart)
		hwy.Store(result, output[ii:])
		x1 := hwy.Load(input[ii+8:])
		expX1 := math.BaseExpVec_neon_Float16(x1)
		expM11 := hwy.SubF16(expX1, vOne)
		negPart1 := hwy.MulF16(vAlpha, expM11)
		isPositive1 := hwy.GreaterThanF16(x1, vZero)
		result1 := hwy.IfThenElseF16(isPositive1, x1, negPart1)
		hwy.Store(result1, output[ii+8:])
	}
	for ; ii+lanes <= size; ii += lanes {
		x := hwy.Load(input[ii:])
		expX := math.BaseExpVec_neon_Float16(x)
		expM1 := hwy.SubF16(expX, vOne)
		negPart := hwy.MulF16(vAlpha, expM1)
		isPositive := hwy.GreaterThanF16(x, vZero)
		result := hwy.IfThenElseF16(isPositive, x, negPart)
		hwy.Store(result, output[ii:])
	}
	for i := ii; i < size; i++ {
		if input[i].Float32() > 0 {
			output[i] = hwy.Float32ToFloat16(input[i].Float32())
		} else {
			x := float64(input[i].Float32())
			output[i] = hwy.Float32ToFloat16(float32(float64(alpha.Float32()) * (stdmath.Exp(x) - 1.0)))
		}
	}
}

func BaseELU_neon_BFloat16(input []hwy.BFloat16, output []hwy.BFloat16, alpha hwy.BFloat16) {
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	vZero := hwy.Set[hwy.BFloat16](actZero_bf16)
	vOne := hwy.Set[hwy.BFloat16](actOne_bf16)
	vAlpha := hwy.Set(alpha)
	lanes := 8
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := hwy.Load(input[ii:])
		expX := math.BaseExpVec_neon_BFloat16(x)
		expM1 := hwy.SubBF16(expX, vOne)
		negPart := hwy.MulBF16(vAlpha, expM1)
		isPositive := hwy.GreaterThanBF16(x, vZero)
		result := hwy.IfThenElseBF16(isPositive, x, negPart)
		hwy.Store(result, output[ii:])
		x1 := hwy.Load(input[ii+8:])
		expX1 := math.BaseExpVec_neon_BFloat16(x1)
		expM11 := hwy.SubBF16(expX1, vOne)
		negPart1 := hwy.MulBF16(vAlpha, expM11)
		isPositive1 := hwy.GreaterThanBF16(x1, vZero)
		result1 := hwy.IfThenElseBF16(isPositive1, x1, negPart1)
		hwy.Store(result1, output[ii+8:])
	}
	for ; ii+lanes <= size; ii += lanes {
		x := hwy.Load(input[ii:])
		expX := math.BaseExpVec_neon_BFloat16(x)
		expM1 := hwy.SubBF16(expX, vOne)
		negPart := hwy.MulBF16(vAlpha, expM1)
		isPositive := hwy.GreaterThanBF16(x, vZero)
		result := hwy.IfThenElseBF16(isPositive, x, negPart)
		hwy.Store(result, output[ii:])
	}
	for i := ii; i < size; i++ {
		if input[i].Float32() > 0 {
			output[i] = hwy.Float32ToBFloat16(input[i].Float32())
		} else {
			x := float64(input[i].Float32())
			output[i] = hwy.Float32ToBFloat16(float32(float64(alpha.Float32()) * (stdmath.Exp(x) - 1.0)))
		}
	}
}

func BaseELU_neon(input []float32, output []float32, alpha float32) {
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	vZero := BaseELU_NEON_vZero_f32
	vOne := BaseELU_NEON_vOne_f32
	vAlpha := asm.BroadcastFloat32x4(alpha)
	lanes := 4
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := asm.LoadFloat32x4((*[4]float32)(unsafe.Pointer(&input[ii])))
		expX := math.BaseExpVec_neon(x)
		expM1 := expX.Sub(vOne)
		negPart := vAlpha.Mul(expM1)
		isPositive := x.Greater(vZero)
		result := x.Merge(negPart, isPositive)
		result.Store((*[4]float32)(unsafe.Pointer(&output[ii])))
		x1 := asm.LoadFloat32x4((*[4]float32)(unsafe.Pointer(&input[ii+4])))
		expX1 := math.BaseExpVec_neon(x1)
		expM11 := expX1.Sub(vOne)
		negPart1 := vAlpha.Mul(expM11)
		isPositive1 := x1.Greater(vZero)
		result1 := x1.Merge(negPart1, isPositive1)
		result1.Store((*[4]float32)(unsafe.Pointer(&output[ii+4])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := asm.LoadFloat32x4((*[4]float32)(unsafe.Pointer(&input[ii])))
		expX := math.BaseExpVec_neon(x)
		expM1 := expX.Sub(vOne)
		negPart := vAlpha.Mul(expM1)
		isPositive := x.Greater(vZero)
		result := x.Merge(negPart, isPositive)
		result.Store((*[4]float32)(unsafe.Pointer(&output[ii])))
	}
	for i := ii; i < size; i++ {
		if input[i] > 0 {
			output[i] = input[i]
		} else {
			x := float64(input[i])
			output[i] = float32(float64(alpha) * (stdmath.Exp(x) - 1.0))
		}
	}
}

func BaseELU_neon_Float64(input []float64, output []float64, alpha float64) {
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	vZero := BaseELU_NEON_vZero_f64
	vOne := BaseELU_NEON_vOne_f64
	vAlpha := asm.BroadcastFloat64x2(alpha)
	lanes := 2
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := asm.LoadFloat64x2((*[2]float64)(unsafe.Pointer(&input[ii])))
		expX := math.BaseExpVec_neon_Float64(x)
		expM1 := expX.Sub(vOne)
		negPart := vAlpha.Mul(expM1)
		isPositive := x.Greater(vZero)
		result := x.Merge(negPart, isPositive)
		result.Store((*[2]float64)(unsafe.Pointer(&output[ii])))
		x1 := asm.LoadFloat64x2((*[2]float64)(unsafe.Pointer(&input[ii+2])))
		expX1 := math.BaseExpVec_neon_Float64(x1)
		expM11 := expX1.Sub(vOne)
		negPart1 := vAlpha.Mul(expM11)
		isPositive1 := x1.Greater(vZero)
		result1 := x1.Merge(negPart1, isPositive1)
		result1.Store((*[2]float64)(unsafe.Pointer(&output[ii+2])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := asm.LoadFloat64x2((*[2]float64)(unsafe.Pointer(&input[ii])))
		expX := math.BaseExpVec_neon_Float64(x)
		expM1 := expX.Sub(vOne)
		negPart := vAlpha.Mul(expM1)
		isPositive := x.Greater(vZero)
		result := x.Merge(negPart, isPositive)
		result.Store((*[2]float64)(unsafe.Pointer(&output[ii])))
	}
	for i := ii; i < size; i++ {
		if input[i] > 0 {
			output[i] = input[i]
		} else {
			x := float64(input[i])
			output[i] = float64(float64(alpha) * (stdmath.Exp(x) - 1.0))
		}
	}
}
