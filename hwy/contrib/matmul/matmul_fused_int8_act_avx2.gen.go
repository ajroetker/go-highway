// Code generated by github.com/ajroetker/go-highway/cmd/hwygen. DO NOT EDIT.

//go:build amd64 && goexperiment.simd

package matmul

import (
	stdmath "math"
	"simd/archsimd"
	"unsafe"

	"github.com/ajroetker/go-highway/hwy/contrib/math"
)

// Hoisted constants - pre-broadcasted at package init time
var (
	BaseFusedInt8MatMulGELUApprox_AVX2_coeff_f32 = archsimd.BroadcastFloat32x8(float32(1.702))
	BaseFusedInt8MatMulGELU_AVX2_half_f32        = archsimd.BroadcastFloat32x8(float32(0.5))
	BaseFusedInt8MatMulGELU_AVX2_invSqrt2_f32    = archsimd.BroadcastFloat32x8(float32(0.7071067811865476))
	BaseFusedInt8MatMulGELU_AVX2_one_f32         = archsimd.BroadcastFloat32x8(float32(1.0))
)

func BaseFusedInt8MatMulSiLU_avx2(input []float32, weights []int8, scales []float32, bias []float32, output []float32, M int, K int, N int, groupSize int) {
	if M == 0 || K == 0 || N == 0 {
		return
	}
	numGroups := (N + groupSize - 1) / groupSize
	lanes := 8
	dequantBuf := [8]float32{}
	accBuf := make([]float32, N)
	for m := range M {
		inputRow := input[m*K : (m+1)*K]
		outputRow := output[m*N : (m+1)*N]
		for i := range N {
			accBuf[i] = 0
		}
		for k := range K {
			inputVal := archsimd.BroadcastFloat32x8(inputRow[k])
			baseIdx := k * N
			scaleBase := k * numGroups
			var n int
			for n = 0; n+lanes <= N; n += lanes {
				for lane := range lanes {
					colIdx := n + lane
					weightIdx := baseIdx + colIdx
					val := float32(weights[weightIdx])
					groupIdx := colIdx / groupSize
					scale := scales[scaleBase+groupIdx]
					dequantBuf[lane] = val * scale
				}
				w := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&dequantBuf[0])))
				acc := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&accBuf[n])))
				acc = inputVal.MulAdd(w, acc)
				acc.Store((*[8]float32)(unsafe.Pointer(&accBuf[n])))
			}
			for ; n < N; n++ {
				weightIdx := baseIdx + n
				val := float32(weights[weightIdx])
				groupIdx := n / groupSize
				scale := scales[scaleBase+groupIdx]
				accBuf[n] += inputRow[k] * val * scale
			}
		}
		var n int
		for n = 0; n+lanes <= N; n += lanes {
			acc := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&accBuf[n])))
			if bias != nil {
				biasVec := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&bias[n])))
				acc = acc.Add(biasVec)
			}
			sig := math.BaseSigmoidVec_avx2(acc)
			acc = acc.Mul(sig)
			acc.Store((*[8]float32)(unsafe.Pointer(&outputRow[n])))
		}
		for ; n < N; n++ {
			sum := accBuf[n]
			if bias != nil {
				sum += bias[n]
			}
			outputRow[n] = sum / (1.0 + float32(stdmath.Exp(float64(-sum))))
		}
	}
}

func BaseFusedInt8MatMulGELU_avx2(input []float32, weights []int8, scales []float32, bias []float32, output []float32, M int, K int, N int, groupSize int) {
	if M == 0 || K == 0 || N == 0 {
		return
	}
	numGroups := (N + groupSize - 1) / groupSize
	lanes := 8
	dequantBuf := [8]float32{}
	accBuf := make([]float32, N)
	for m := range M {
		inputRow := input[m*K : (m+1)*K]
		outputRow := output[m*N : (m+1)*N]
		for i := range N {
			accBuf[i] = 0
		}
		for k := range K {
			inputVal := archsimd.BroadcastFloat32x8(inputRow[k])
			baseIdx := k * N
			scaleBase := k * numGroups
			var n int
			for n = 0; n+lanes <= N; n += lanes {
				for lane := range lanes {
					colIdx := n + lane
					weightIdx := baseIdx + colIdx
					val := float32(weights[weightIdx])
					groupIdx := colIdx / groupSize
					scale := scales[scaleBase+groupIdx]
					dequantBuf[lane] = val * scale
				}
				w := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&dequantBuf[0])))
				acc := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&accBuf[n])))
				acc = inputVal.MulAdd(w, acc)
				acc.Store((*[8]float32)(unsafe.Pointer(&accBuf[n])))
			}
			for ; n < N; n++ {
				weightIdx := baseIdx + n
				val := float32(weights[weightIdx])
				groupIdx := n / groupSize
				scale := scales[scaleBase+groupIdx]
				accBuf[n] += inputRow[k] * val * scale
			}
		}
		var n int
		for n = 0; n+lanes <= N; n += lanes {
			acc := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&accBuf[n])))
			if bias != nil {
				biasVec := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&bias[n])))
				acc = acc.Add(biasVec)
			}
			invSqrt2 := BaseFusedInt8MatMulGELU_AVX2_invSqrt2_f32
			half := BaseFusedInt8MatMulGELU_AVX2_half_f32
			one := BaseFusedInt8MatMulGELU_AVX2_one_f32
			scaled := acc.Mul(invSqrt2)
			erfVal := math.BaseErfVec_avx2(scaled)
			acc = acc.Mul(half.Mul(one.Add(erfVal)))
			acc.Store((*[8]float32)(unsafe.Pointer(&outputRow[n])))
		}
		for ; n < N; n++ {
			sum := accBuf[n]
			if bias != nil {
				sum += bias[n]
			}
			outputRow[n] = sum * 0.5 * (1.0 + float32(stdmath.Erf(float64(sum)*0.7071067811865476)))
		}
	}
}

func BaseFusedInt8MatMulGELUApprox_avx2(input []float32, weights []int8, scales []float32, bias []float32, output []float32, M int, K int, N int, groupSize int) {
	if M == 0 || K == 0 || N == 0 {
		return
	}
	numGroups := (N + groupSize - 1) / groupSize
	lanes := 8
	dequantBuf := [8]float32{}
	accBuf := make([]float32, N)
	for m := range M {
		inputRow := input[m*K : (m+1)*K]
		outputRow := output[m*N : (m+1)*N]
		for i := range N {
			accBuf[i] = 0
		}
		for k := range K {
			inputVal := archsimd.BroadcastFloat32x8(inputRow[k])
			baseIdx := k * N
			scaleBase := k * numGroups
			var n int
			for n = 0; n+lanes <= N; n += lanes {
				for lane := range lanes {
					colIdx := n + lane
					weightIdx := baseIdx + colIdx
					val := float32(weights[weightIdx])
					groupIdx := colIdx / groupSize
					scale := scales[scaleBase+groupIdx]
					dequantBuf[lane] = val * scale
				}
				w := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&dequantBuf[0])))
				acc := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&accBuf[n])))
				acc = inputVal.MulAdd(w, acc)
				acc.Store((*[8]float32)(unsafe.Pointer(&accBuf[n])))
			}
			for ; n < N; n++ {
				weightIdx := baseIdx + n
				val := float32(weights[weightIdx])
				groupIdx := n / groupSize
				scale := scales[scaleBase+groupIdx]
				accBuf[n] += inputRow[k] * val * scale
			}
		}
		var n int
		for n = 0; n+lanes <= N; n += lanes {
			acc := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&accBuf[n])))
			if bias != nil {
				biasVec := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&bias[n])))
				acc = acc.Add(biasVec)
			}
			coeff := BaseFusedInt8MatMulGELUApprox_AVX2_coeff_f32
			scaled := acc.Mul(coeff)
			sig := math.BaseSigmoidVec_avx2(scaled)
			acc = acc.Mul(sig)
			acc.Store((*[8]float32)(unsafe.Pointer(&outputRow[n])))
		}
		for ; n < N; n++ {
			sum := accBuf[n]
			if bias != nil {
				sum += bias[n]
			}
			outputRow[n] = sum / (1.0 + float32(stdmath.Exp(float64(-1.702*sum))))
		}
	}
}

func BaseFusedInt8MatMulReLU_avx2(input []float32, weights []int8, scales []float32, bias []float32, output []float32, M int, K int, N int, groupSize int) {
	if M == 0 || K == 0 || N == 0 {
		return
	}
	numGroups := (N + groupSize - 1) / groupSize
	lanes := 8
	dequantBuf := [8]float32{}
	accBuf := make([]float32, N)
	for m := range M {
		inputRow := input[m*K : (m+1)*K]
		outputRow := output[m*N : (m+1)*N]
		for i := range N {
			accBuf[i] = 0
		}
		for k := range K {
			inputVal := archsimd.BroadcastFloat32x8(inputRow[k])
			baseIdx := k * N
			scaleBase := k * numGroups
			var n int
			for n = 0; n+lanes <= N; n += lanes {
				for lane := range lanes {
					colIdx := n + lane
					weightIdx := baseIdx + colIdx
					val := float32(weights[weightIdx])
					groupIdx := colIdx / groupSize
					scale := scales[scaleBase+groupIdx]
					dequantBuf[lane] = val * scale
				}
				w := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&dequantBuf[0])))
				acc := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&accBuf[n])))
				acc = inputVal.MulAdd(w, acc)
				acc.Store((*[8]float32)(unsafe.Pointer(&accBuf[n])))
			}
			for ; n < N; n++ {
				weightIdx := baseIdx + n
				val := float32(weights[weightIdx])
				groupIdx := n / groupSize
				scale := scales[scaleBase+groupIdx]
				accBuf[n] += inputRow[k] * val * scale
			}
		}
		var n int
		for n = 0; n+lanes <= N; n += lanes {
			acc := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&accBuf[n])))
			if bias != nil {
				biasVec := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&bias[n])))
				acc = acc.Add(biasVec)
			}
			acc = acc.Max(archsimd.BroadcastFloat32x8(0))
			acc.Store((*[8]float32)(unsafe.Pointer(&outputRow[n])))
		}
		for ; n < N; n++ {
			sum := accBuf[n]
			if bias != nil {
				sum += bias[n]
			}
			outputRow[n] = float32(stdmath.Max(0, float64(sum)))
		}
	}
}
